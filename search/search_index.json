{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"XAD Documentation","text":"<p>See below for the contents of the XAD documentation. Note that you can access the full documentation easier on auto-differentiation.github.io.</p> <ul> <li>Getting Started</li> <li>Tutorials<ul> <li>Basic Usage</li> <li>External Functions</li> <li>Checkpointing</li> <li>Higher-Order Derivatives</li> <li>Handling Discontinuities</li> </ul> </li> <li>Reference:<ul> <li>Headers and Namespaces</li> <li>AD Mode Interface</li> <li>Forward Mode Type FReal</li> <li>Adjoint Mode Type AReal</li> <li>Global Functions</li> <li>Mathematical Operations</li> <li>Complex</li> <li>Smoothed Mathematical Functions</li> <li>Expressions</li> <li>Tape</li> <li>CheckpointCallback</li> <li>Exceptions</li> <li>Version Information</li> </ul> </li> <li>Examples</li> <li>AD Background</li> <li>QuantLib Integration</li> <li>About</li> </ul>"},{"location":"aad/","title":"Algorithmic Differentiation Background","text":"<p>As every computer program is made up of a series of simple arithmetic operations, i.e.</p> \\[ a \\rightarrow b \\rightarrow \\ldots \\rightarrow u \\rightarrow v \\rightarrow \\ldots \\rightarrow z \\] <p>where the inputs \\(a\\) are modified in stages in order to get the final output \\(z\\). When the individual derivatives of each operation are known, the final derivative can be computed by recursive application of the chain rule. This is method is called Algorithmic Differentiation, with the modes forward (or tangent-linear), i.e., from inputs to outputs, and adjoint (or reverse) mode, i.e., from outputs to inputs.</p> <p>In this section, we introduce the underlying theory for computing derivatives of a computer program. We start with a review of the traditional finite difference method, often called bumping, before introducing forward and adjoint algorithmic differentiation.</p>"},{"location":"aad/#finite-differences","title":"Finite Differences","text":"<p>The traditional approach for computing these derivatives is by employing a finite difference approximation. That is, each of the input variables are bumped one by one and the change of the result is used to estimate the sensitivities:</p> \\[ \\begin{align} \\frac{\\partial f(x, \\pmb{y})}{\\partial x} &amp;= \\lim_{h\\rightarrow 0}\\frac{f(x+h, \\pmb{y}) - f(x,\\pmb{y})}{h}  \\\\ \\frac{\\partial f(x, \\pmb{y})}{\\partial x} &amp;= \\lim_{h\\rightarrow 0} \\frac{f(x+h, \\pmb{y}) - f(x-h, \\pmb{y})}{2h} \\end{align} \\] <p>where \\(f(x, \\pmb{y})\\) is the function of which we are interested in derivatives with respect to the input parameter \\(x\\). The vector-valued argument \\(\\pmb{y}\\) denotes the remaining function parameters. The first equation represents forward finite differences and requires two evaluations of the function. The second equation gives central finite differences with potentially higher accuracy and requires two function evaluation for the derivative and another evaluation for the function's value.</p> <p>In practice, the value \\(h\\) is chosen small enough to approximate the theoretical limit, but large enough to cause a detectable change of the result beyond typical numerical error levels. Clearly, this choice impacts the accuracy of the approximation.</p> <p>Further, this method implies that the function needs to be evaluated once for the result and once for each derivative that we are interested in. This results in a high overall computational complexity as soon as more than a few derivatives are needed.</p> <p>Thus, the finite differences approach has accuracy and performance limitations.</p>"},{"location":"aad/#forward-mode","title":"Forward Mode","text":""},{"location":"aad/#theory","title":"Theory","text":"<p>The forward mode defines \\(\\dot{u}\\) as the derivative of \\(u\\) with respect to \\(a\\), i.e.</p> \\[ \\dot{u} = \\frac{\\partial u}{\\partial a} \\] <p>Applying the chain rule of differentiation and assuming that the intermediate variables are vectors, the elements of \\(\\dot{v}\\) can be calculated as</p> \\[ \\dot{v}_i = \\sum_j \\frac{\\partial v_i}{\\partial u_{j}} \\dot{u}_j \\] <p>Applying this to each step in the chain of operations from inputs to outputs, the value of \\(\\dot{z}\\) can be calculated. This is the forward mode of algorithmic differentiation.</p> <p>For a function \\(f,{:},\\mathbb{R}^n,{\\rightarrow},\\mathbb{R}^m\\), one application of the forward mode gives the sensitivities for all \\(m\\) outputs with respect to one input parameter. It needs to be re-evaluated \\(n\\) times to obtain all sensitivities. The computational cost is constant in the number of output variables \\(m\\) and linear in the number of input variables \\(n\\).</p>"},{"location":"aad/#example","title":"Example","text":"<p>We illustrate the forward mode on the example function:</p> \\[ z = \\sin x_1 + x_1 x_2 \\] <p>Which can be implemented in a computer program as:</p> <pre><code>a = sin(x1);\nb = x1 * x2;\nz = a + b;\n</code></pre> <p>We are interested of the derivative with respect to \\(x_1\\) for the input values \\(x_1 = \\pi\\) and \\(x_2 = 2\\). The following figure illustrates how the forward mode algorithm differentiation is applied to this problem:</p> <p></p> <p>On the left we see the computational graph representing the equation, and the table on the right illustrates the the steps performed.</p> <p>In step 0, we initialize the input values and we seed the derivatives of these inputs. As we are interested in the derivative w.r.t. \\(x_1\\), we set its derivative to 1 while setting the other to 0.</p> <p>Next we compute \\(a\\) by taking the sine function. The value of \\(a\\) is zero, while \\(\\dot{a}\\) is computed by multiplying the partial derivative of the sine w.r.t. to \\(x_1\\), i.e. the cosine, with \\(\\dot{x_1}\\). This gives a value of -1.</p> <p>In the next step, the value of \\(b\\) is computed as usual, and \\(\\dot{b}\\) is calculated similarly to \\(\\dot{a}\\), this time depending on both  \\(\\dot{x_1}\\) and \\(\\dot{x_2}\\). This results in a value of 2.</p> <p>The final statement adds both \\(a\\) and \\(b\\), which gives the result of \\(2\\pi\\). To calculate \\(\\dot{z}\\), we see that the  \\(\\dot{a}\\) and \\(\\dot{b}\\) can simply be added since their partial derivatives are both 1. This gives a final derivative of 1.</p> <p>Hence:</p> \\[ \\left.\\frac{\\partial z}{\\partial x_1}\\right|_{(\\pi,2)} = 1 \\] <p>which can be easily verified analytically.</p>"},{"location":"aad/#adjoint-mode","title":"Adjoint Mode","text":""},{"location":"aad/#theory_1","title":"Theory","text":"<p>The adjoint mode applies the chain rule backwards, from outputs to inputs. Using standard notation, we define</p> \\[ \\bar{u}_i = \\frac{\\partial z}{\\partial u_i} \\] <p>where \\(i\\) is the index in the vector \\(\\pmb{u}\\). Applying the chain rule yields</p> \\[ \\frac{\\partial z}{\\partial u_i} = \\sum_j \\frac{\\partial z}{\\partial v_j} \\frac{\\partial v_j}{\\partial u_i} \\] <p>which leads to the adjoint mode equation</p> \\[ \\bar{u}_i    =  \\sum_j \\frac{\\partial v_j}{\\partial u_i} \\bar{v}_j \\] <p>Seeding \\(\\bar{z} = 1\\), the adjoint mode equation can be applied for each step, from output to input, to obtain \\(\\bar{\\pmb{a}}\\), which is the derivative of the output \\(z\\) with respect to each of the input variables \\(\\pmb{a}\\).</p> <p>For a function \\(f,{:},\\mathbb{R}^n,{\\rightarrow},\\mathbb{R}^m\\), the adjoint mode gives the sensitivities of one output with respect to all \\(n\\) input parameters. It needs to be re-evaluated \\(m\\) times to obtain all sensitivities. The computational cost is constant in the number of input variables \\(n\\) and linear in the number of output variables \\(m\\).</p>"},{"location":"aad/#example_1","title":"Example","text":"<p>We illustrate the adjoint mode using the same example as above:</p> \\[ z = \\sin x_1 + x_1 x_2 \\] <p>implemented as:</p> <pre><code>a = sin(x1);\nb = x1 * x2;\nz = a + b;\n</code></pre> <p>With adjoint mode, we can get both partial derivatives of the output in a single execution, for the input values \\(x_1 = \\pi\\) and \\(x_2 = 2\\). This is illustrated in the figure below:</p> <p></p> <p>As the adjoint mode walks from outputs back to inputs, we execute the full computation of the value as usual, until we have an output for \\(z\\) of \\(2\\pi\\).</p> <p>Then we seed the adjoint of \\(z\\) to 1 in the final step, and walk backwards to compute the adjoints of the inputs.</p> <p>In step 2, we can compute the adjoint of \\(b\\) by multiplying the adjoint of \\(z\\) with the partial derivative of the equation for \\(z\\) w.r.t. \\(b\\), which is 1.</p> <p>The same is performed in step 1 to compute the adjoint of \\(a\\), which also yields 1.</p> <p>The adjoint of \\(x_2\\) is then computed by multiplying the partial derivative of \\(b\\) w.r.t. \\(x_2\\) with the adjoint of \\(b\\), which gives the value \\(\\pi\\).</p> <p>The same method is applied to compute the adjoint of \\(x_1\\), giving the value 1.</p> <p>Thus, the two derivatives we were interested in are:</p> \\[ \\begin{align} \\left.\\frac{\\partial z}{\\partial x_1}\\right|_{(\\pi,2)} &amp;= 1 &amp;,&amp;&amp; \\left.\\frac{\\partial z}{\\partial x_2}\\right|_{(\\pi,2)} &amp;= \\pi \\end{align} \\] <p>Which can be easily verified analytically.</p>"},{"location":"aad/#higher-orders","title":"Higher Orders","text":"<p>Higher order derivatives can be obtained by nesting the principles described above. For example, applying forward mode algorithmic differentiation over adjoint mode gives second order derivatives. This method can be extended to any order.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#history","title":"History","text":"<p>In 2010, Xcelerit started working on AAD, building on early works of Professor Mike Giles and Professor Paul Glasserman for efficiently calculating greeks in quantitative finance with AAD. Xcelerit's closed-source tool QuantAD was first released in 2014, targeting the quantitative finance industry. The tool evolved over the years with more features and better performance. In July 2022, Xcelerit generalised it so it can be used in other industries and published it as an open-source tool, rebranded as XAD 1.0.0.</p>"},{"location":"about/#logo-and-name","title":"Logo and Name","text":"<p>The XAD logo is typeset using the standard LaTeX Computer Modern Math font, using the expression <code>$xa\\partial$</code>. The logo's html color code is <code>#FBBA17</code>.</p> <p>The name XAD is spelled with all capitals.</p>"},{"location":"about/#authors","title":"Authors","text":"<ul> <li>Various contributors from Xcelerit</li> <li>See also the list of contributors who participated in the project.</li> </ul>"},{"location":"about/#getting-in-touch","title":"Getting In Touch","text":"<p>If you have found an issue, want to report a bug, or have a feature request, please raise a GitHub issue.</p> <p>For general questions about XAD, sharing ideas, engaging with community members, etc, please use GitHub Discussions.</p>"},{"location":"about/#license-information","title":"License Information","text":"<p>Whether you are carrying out early stage R\\&amp;D, prototyping or large scale deployment, our flexible licensing options will meet your needs at every stage of the journey. XAD allows anyone to get started with its AGPL license while Xcelerit provides commercial source-code licenses to support development and delivery of enterprise applications.</p> <p>Please get in touch for commercial licensing and support options.</p>"},{"location":"examples/","title":"Examples","text":"<p>To quickly get an idea how using XAD looks like in practice, see the examples below. All code snippets require that the function to be differentiated is callable with the active data type for algorithmic differentiation.</p> <p>Note that XAD ships with a set of examples that can be used as a starting point for development. Further, for examples how to use it with a large-scale project, please see QuantLib Integration.</p>"},{"location":"examples/#first-order-forward-mode","title":"First Order Forward Mode","text":"<pre><code>// types for first-order forward mode in double precision\nusing mode = xad::fwd&lt;double&gt;;\nusing Adouble = mode::active_type;\n// independent variables\nAdouble x0 = 1.0, x1 = 1.5, x2 = 1.3, x3 = 1.2;  derivative(x0) = 1.0;   // seed directional derivative\n// (calculate dy/dx0)\nAdouble y = func(x0, x1, x2, x3); std::cout &lt;&lt; \"y      = \" &lt;&lt; value(y) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx0 = \" &lt;&lt; derivative(y) &lt;&lt; \"\\n\";\n</code></pre>"},{"location":"examples/#first-order-adjoint-mode","title":"First Order Adjoint Mode","text":"<pre><code>// types for first-order adjoints in double precision\nusing mode = xad::adj&lt;double&gt;;\nusing Adouble = mode::active_type;\nusing Tape = mode::tape_type;\nTape tape;\n// independent variables and start taping\nstd::vector&lt;Adouble&gt; x ={1.0, 1.5, 1.3, 1.2};  tape.registerInputs(x);\ntape.newRecording();\nAdouble y = func(x[0], x[1], x[2], x[3]);\ntape.registerOutput(y);\nderivative(y) = 1.0;        // seed output adjoint\ntape.computeAdjoints();     // roll-back tape\nstd::cout &lt;&lt; \"y      = \" &lt;&lt; value(y) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx0 = \" &lt;&lt; derivative(x[0]) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx1 = \" &lt;&lt; derivative(x[1]) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx2 = \" &lt;&lt; derivative(x[2]) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx3 = \" &lt;&lt; derivative(x[3]) &lt;&lt; \"\\n\";\n</code></pre>"},{"location":"examples/#second-order-forward-over-adjoint-mode","title":"Second Order Forward over Adjoint Mode","text":"<pre><code>// types for second-order foward-over-adjoint in double\nusing mode = xad::fwd_adj&lt;double&gt;;\nusing Adouble = mode::active_type;\nusing Tape = mode::tape_type;\nTape tape;\n// independent variables\nstd::vector&lt;Adouble&gt; x = {1.0, 1.5, 1.3, 1.2};  // seed directional derivative for 2nd order forward\nderivative(value(x0)) = 1.0;  // register inputs on tape and record function calls\ntape.registerInputs(x);     tape.newRecording();        Adouble y = func(x0, x1, x2, x3);\nvalue(derivative(y)) = 1.0; // seed 1st order adjoint\ntape.computeAdjoints();     // roll-back tape\nstd::cout &lt;&lt; \"y      = \" &lt;&lt; value(value(y)) &lt;&lt; \"\\n\"\n&lt;&lt; \"\\nfirst order derivatives:\\n\"\n&lt;&lt; \"dy/dx0 = \" &lt;&lt; value(derivative(x[0])) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx1 = \" &lt;&lt; value(derivative(x[1])) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx2 = \" &lt;&lt; value(derivative(x[2])) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx3 = \" &lt;&lt; value(derivative(x[3])) &lt;&lt; \"\\n\"\n&lt;&lt; \"\\nsecond order derivatives w.r.t. x0:\\n\"\n&lt;&lt; \"d2y/dx0dx0 = \" &lt;&lt; derivative(derivative(x[0])) &lt;&lt; \"\\n\"\n&lt;&lt; \"d2y/dx0dx1 = \" &lt;&lt; derivative(derivative(x[1])) &lt;&lt; \"\\n\"\n&lt;&lt; \"d2y/dx0dx2 = \" &lt;&lt; derivative(derivative(x[2])) &lt;&lt; \"\\n\"\n&lt;&lt; \"d2y/dx0dx3 = \" &lt;&lt; derivative(derivative(x[3])) &lt;&lt; \"\\n\";\n</code></pre> <pre><code>Adouble x0 = 1.3, x1 = 5.2;  tape.registerInput(x0); tape.registerInput(x1);\ntape.newRecording(); Adouble y = func(x0, x1);\ntape.registerOutput(y);\nderivative(y) = 1.0;\ntape.computeAdjoints();\ncout &lt;&lt; \"dy/dx0=\" &lt;&lt; derivative(x0) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx1=\" &lt;&lt; derivative(x1) &lt;&lt; \"\\n\";\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#building-xad","title":"Building XAD","text":""},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<ul> <li>CMake, version 3.15 or newer</li> <li>Linux: GCC 5.4 or newer, or Clang 11 or newer</li> <li>Windows:<ul> <li>Visual Studio 2015 or newer</li> <li>Visual Studio with Clang toolset, 2019 or newer</li> </ul> </li> <li>MacOS: 10.9 or higher, with Apple Clang 11 or newer</li> <li>Git client</li> </ul> <p>(See tested platforms for the list of platforms covered by continuous integration.)</p>"},{"location":"getting_started/#cloning-the-repository","title":"Cloning the Repository","text":"<pre><code>    git clone https://github.com/auto-differentiation/XAD.git\n</code></pre>"},{"location":"getting_started/#building","title":"Building","text":"<ol> <li>Create a directory for the build artefacts     <pre><code>cd XAD\nmkdir build\ncd build\n</code></pre></li> <li>Run cmake to generate the build files     <pre><code>cmake ..\n</code></pre></li> <li>Build using the native build system or with the generic cmake build command     <pre><code>cmake --build .\n</code></pre></li> </ol>"},{"location":"getting_started/#running-the-tests","title":"Running the tests","text":"<p>The tests are executed with the <code>test</code> target:</p> <pre><code>cmake --build . --target test\n</code></pre> <p>Alternatively, <code>ctest</code> can be used to run them:</p> <pre><code>ctest\n</code></pre> <p>Or if only the unit tests should be run, the <code>xad_test</code> executable in the bin directory can be executed directly.</p>"},{"location":"getting_started/#installing","title":"Installing","text":"<p>Run the <code>install</code> build target to place the header files, library files, docs, and samples into the <code>CMAKE_INSTALL_PREFIX</code> (configurable with CMake).</p> <pre><code>cmake --install .\n</code></pre>"},{"location":"getting_started/#integration-approaches","title":"Integration Approaches","text":"<p>In order to use XAD as part of other code, we recommend one of the following approaches.</p>"},{"location":"getting_started/#1-submodule-cmake","title":"1: Submodule + CMake","text":"<p>If your codebase is using CMake, XAD can be integrated easily into your project by adding it as a git submodule.</p> <p>To add the submodule in a subdirectory <code>extern/XAD</code>:</p> <pre><code>git submodule add https://github.com/auto-differentiation/XAD.git extern/XAD\n</code></pre> <p>Users then need to clone recursively (<code>git clone --recursive ...</code>) or initialise and update the submodules (<code>git submodule init &amp;&amp; git submodule update</code>). More information about submodules can be found in the Git documentation.</p> <p>To add XAD to the project, all that is needed in one of the <code>CMakeLists.txt</code> files is to add the xad directory, and then link the relevant libraries or executables to <code>XAD::xad</code>:</p> <pre><code>add_subdirectory(extern/XAD)\nadd_executable(some_executable ...)\ntarget_link_libraries(some_executable PRIVATE XAD::xad)\n</code></pre>"},{"location":"getting_started/#2-fetchcontent-cmake","title":"2: FetchContent + CMake","text":"<p>The CMake FetchContent module allows to clone the git repository at configure-time into the build folder and add it to your project after:</p> <pre><code>include(FetchContent)\nFetchContent_Declare(XAD\nGIT_REPOSITORY https://github.com/auto-differentiation/XAD.git\nGIT_TAG 1.1.0    # pick a tag, hash, or branch here\n)\nFetchContent_MakeAvailable(XAD)\n</code></pre> <p>Note that this requires at least CMake version 3.14.</p>"},{"location":"getting_started/#3-install-xad-and-link","title":"3: Install XAD and Link","text":"<p>Another approach is to install XAD into a convenient prefix (e.g. <code>/usr/local/</code>) first (instructions above, setting <code>CMAKE_INSTALL_PREFIX</code> appropriately). Note that the package can also be zipped on one machine and downloaded/extracted on another.</p> <p>Important: Since XAD is built as a static library, be careful to use the same compiler and flags for your project as well as XAD itself. Otherwise the binaries may not be compatible. We therefore recommend to the subproject approach, building from source within your project. The library builds very fast.</p>"},{"location":"getting_started/#cmake","title":"CMake","text":"<p>Then, when you use CMake, you can setup your project to find the XAD dependency in a <code>CMakeLists.txt</code> file as:</p> <pre><code>find_package(XAD REQUIRED)\n</code></pre> <p>If XAD is installed in a standard location, CMake automatically looks for it there and finds it. Otherwise, the <code>CMAKE_PREFIX_PATH</code> variable can be set at configure-time to add a different directory to its search path:</p> <pre><code>cmake /path/to/src -DCMAKE_PREFIX_PATH=/path/to/XAD/installprefix\n</code></pre>"},{"location":"getting_started/#other-build-tools","title":"Other Build Tools","text":"<p>If your project does not use CMake, an installed package can also be linked by adding the following settings:</p> <ul> <li>Add <code>/path/to/XAD/include</code> to the compiler's include path</li> <li>Enable at least C++ 11 support (<code>-std=c++11</code> in GCC)</li> <li>Enable threading (requires <code>-pthread</code> in GCC for compile and link)</li> <li>Add the library path <code>/path/to/XAD/lib</code> to the linker search paths</li> <li>Link <code>libxad.a</code> (Release) or <code>libxad_d.a</code> (Debug) - or the alternative names on Windows</li> </ul>"},{"location":"getting_started/#tuning-behaviour-and-performance","title":"Tuning Behaviour and Performance","text":"<p>A number of options are available via CMake to control the build and tune the performance. They can be specified using the CMake command-line with <code>-DVARIABLE=value</code>, or with the CMake GUI.</p> <p>Influential variables controlling the build are:</p> Variable Description Default <code>XAD_ENABLE_TESTS</code> Enable building tests and samples. <code>ON</code> if main project<code>OFF</code> if sub project <code>XAD_WARNINGS_PARANOID</code> Enable a high warning level and flag warnings as errors. <code>ON</code> <code>XAD_STATIC_MSVC_RUNTIME</code> Use the static multi-threaded runtime in Visual C++ (default is dynamic) <code>XAD_POSITION_INDEPENDENT_CODE</code> Generate position-indepent code, i.e. allow linking into a shared library. <code>ON</code> <code>XAD_ENABLE_ADDRESS_SANITIZER</code> Enable address sanitizer (leak detector) - GCC/Clang only. <code>OFF</code> <p>Options with an impact on the performance of the tape in adjoint mode (application-specific). These should not be changed in client code after the tape has been compiled:</p> Variable Description Default <code>XAD_SIMD_OPTION</code> Select between <code>SSE2</code>, <code>AVX</code>, <code>AVX2</code>, and <code>AVX512</code> instruction sets. Only enable what the target CPU supports. <code>AVX</code> <code>XAD_TAPE_REUSE_SLOTS</code> Keep track of unused slots in tape and re-use them (less memory, more compute) <code>OFF</code> <code>XAD_NO_THREADLOCAL</code> Disable thread-local tapes (use with single-threaded code only <code>OFF</code> <p>Options that can be set by client code as well, adjusting settings after the XAD library has already been compiled (in <code>Config.hpp</code> or client code compiler definitions):</p> Variable Description Default <code>XAD_USE_STRONG_INLINE</code> Force inlining expression templates, rather than letting the compiler decide. (faster, slow compilation, possible compiler crashes) <code>OFF</code> <code>XAD_ALLOW_INT_CONVERSION</code> Add real -&gt; integer conversion operator, similar to <code>double</code>. This may result missing some variable dependency tracking for AAD. <code>ON</code>"},{"location":"getting_started/#building-the-documentation","title":"Building the Documentation","text":"<p>The user documentation uses the popular MkDocs Material tool. It is entirely generated from the markdown files located in the <code>docs</code> folder.</p>"},{"location":"getting_started/#approach-1-docker","title":"Approach 1: Docker","text":"<p>The docs can be generated easily using docker by running in the project root:</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material\n</code></pre> <p>This will serve the documentation on http://127.0.0.1:8000 and watch for changes in the <code>docs</code> folder automatically. The files can now be modified and conveniently viewed.</p>"},{"location":"getting_started/#approach-2-local-python","title":"Approach 2: Local Python","text":"<p>Alternatively, MkDocs can be installed locally into a python environment and executed as follows  (we recommend a virtual environment as shown below).</p> <ol> <li>Setup the environment and dependencies:      <pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install mkdocs-material mkdocs-minify-plugin mkdocs-redirects \"pillow&lt;10\" \"cairosvg&gt;=2.5\"\n</code></pre></li> <li>Run mkdocs (in the activated environment):     <pre><code>mkdocs serve\n</code></pre></li> </ol> <p>This will also serve the documentation locally on http://127.0.0.1:8000 and watch for changes in the <code>docs</code> folder automatically.</p>"},{"location":"getting_started/#getting-help","title":"Getting Help","text":"<p>If you have found an issue, want to report a bug, or have a feature request, please raise a GitHub issue.</p> <p>For general questions about XAD, sharing ideas, engaging with community members, etc, please use GitHub Discussions.</p>"},{"location":"getting_started/#tested-platforms","title":"Tested Platforms","text":"<p>The following platforms are part of the continuous integration workflow, i.e. they are tested on each commit. You can use other configurations at your own risk, or submit a PR to include it in the CI workflow.</p> Operating System Compiler Configurations Test Coverage Recorded Windows Server 2019 Visual Studio 2015 (Toolset 14.0) Debug, Release no Windows Server 2022 Visual Studio 2017 (Toolset 14.1) Debug, Release no Windows Server 2022 Visual Studio 2019 (Toolset 14.2) Debug, Release no Windows Server 2022 Visual Studio 2022 (Toolset 14.3) Debug, Release no Windows Server 2022 Clang 14.0         (Toolset 14.3) Debug, Release no Ubuntu 16.04 GCC 5.4.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 17.10 GCC 6.4.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 17.10 GCC 7.2.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 18.04 GCC 8.4.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 19.10 GCC 9.2.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 20.04 GCC 10.3.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 20.04 GCC 11.1.0 Debug, Release, + both with <code>XAD_TAPE_REUSE_SLOTS</code> yes Ubuntu 20.04 Clang 11.0.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 22.04 Clang 12.0.1 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 22.04 Clang 13.0.1 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no Ubuntu 22.04 Clang 14.0.0 Debug, Release, Release with <code>XAD_TAPE_REUSE_SLOTS</code> no MacOS 12.6.5 AppleClang 14.0.0 Debug, Release yes"},{"location":"quantlib/","title":"QuantLib Integration","text":"<p>As a demonstrator of integration with real-world code, the latest release of QuantLib is AAD-enabled with XAD. The performance achieved on sample applications is many-fold superior to what has been reported previously with other tools. This demonstrates production quality use of the XAD library in a code-base of several hundred thousand lines.</p> <p>A small adaptor module (also open-source) is required between the two projects, which contains build instructions as well as XAD-specific tests and examples.</p>"},{"location":"quantlib/#getting-started","title":"Getting Started","text":""},{"location":"quantlib/#1-repository-clonecheckout","title":"1. Repository Clone/Checkout","text":"<p>Clone these three repositories into separate folders:</p> <ul> <li>https://github.com/auto-differentiation/qlxad.git</li> <li>https://github.com/auto-differentiation/XAD.git</li> <li>https://github.com/lballabio/QuantLib.git</li> </ul> <p>Note: We recommend either using the lastest master branch for all repositories involved. These are tested against each other on a daily basis and errors are corrected quickly.</p>"},{"location":"quantlib/#2-install-boost","title":"2. Install Boost","text":"<p>A recent version of boost is a requirement for building QuantLib. If you do not have it already, you need to install it into a system path. You can do that in one of the following ways, depending on your system:</p> <ul> <li>Ubuntu or Debian: <code>sudo apt install libboost-all-dev</code></li> <li>Fedora or RedHat: <code>sudo yum install boost-devel</code></li> <li>MacOS using Homebrew: <code>brew install boost</code></li> <li>MacOS using Mac Ports: <code>sudo port install boost</code></li> <li> <p>Windows using Chocolatey:</p> <ul> <li>For Visual Studio 2022: <code>choco install boost-msvc-14.3</code></li> <li>For Visual Studio 2019: <code>choco install boost-msvc-14.2</code></li> <li>For Visual Studio 2017: <code>choco install boost-msvc-14.1</code></li> </ul> </li> <li> <p>Windows using manual installers: Boost Binaries on SourceForge</p> </li> </ul>"},{"location":"quantlib/#3-install-cmake","title":"3. Install CMake","text":"<p>You will also need a recent version of CMake (minimum version 3.15.0). You can also install this with your favourite package manager (e.g. apt, yum, homebrew, chocolatey as above), or obtain it from the CMake downloads page.</p> <p>Note that Microsoft ships Visual Studio with a suitable version command-line only version of CMake since Visual Studio 2019 (the Visual Studio 2017 CMake version is outdated). It is available in the <code>PATH</code> from a Visual Studio command prompt and can alternatively be used directly from the IDE.</p>"},{"location":"quantlib/#4-quantlib-cmake-configuration","title":"4. QuantLib CMake Configuration","text":"<p>The build is driven from the QuantLib directory - XAD and qlxad are inserted using QuantLib's extension hook.</p> <p>Configure the QuantLib CMake build with setting the following parameters:</p> <ul> <li><code>QL_EXTERNAL_SUBDIRECTORIES=/path/to/xad;/path/to/qlxad</code></li> <li><code>QL_EXTRA_LINK_LIBRARIES=qlxad</code></li> <li><code>QL_NULL_AS_FUNCTIONS=ON</code></li> <li><code>XAD_STATIC_MSVC_RUNTIME=ON</code></li> </ul> <p>For Linux, the command-line for this is:</p> <pre><code>cd QuantLib\nmkdir build\ncd build\ncmake .. -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=Release \\\n-DQL_EXTERNAL_SUBDIRECTORIES=\"`pwd`/../../xad;`pwd`/../../qlxad\" \\\n-DQL_EXTRA_LINK_LIBRARIES=qlxad \\\n-DQL_NULL_AS_FUNCTIONS=ON \\\n-DXAD_STATIC_MSVC_RUNTIME=ON\n</code></pre> <p>In Windows, you can use the CMake GUI to generate the build files, setting the same variables as above.</p>"},{"location":"quantlib/#5-building","title":"5. Building","text":"<p>The generated build files can now be built using the regular native build tools. For example, in Linux <code>make</code> can be run, and in Visual Studio, the solution can be opened and built. Note that we recommend Release mode for Windows builds.</p>"},{"location":"quantlib/#6-running-the-tests","title":"6. Running the Tests","text":"<p>There are two test executables that get built - the regular QuantLib test suite with all the standard tests from the mainline repository, as well as the QuantLib XAD test suite from the qlxad repository. Both are using the overloaded XAD type for <code>double</code>, but only the XAD suite checks for the correctness of the derivatives as well.</p> <p>These executables can simply be run to execute all the tests. We recommend to use the parameter <code>--log_level=message</code> to see the test progress. Alternatively, CTest can also be used to execute them.</p>"},{"location":"quantlib/#7-running-the-examples","title":"7. Running the Examples","text":"<p>Apart from the regular QuantLib examples, there are XAD-specific examples in the qlxad repository, in the <code>Examples</code> folder. These demonstrate the use of XAD to calculate derivatives using AAD.</p>"},{"location":"quantlib/#benchmarks","title":"Benchmarks","text":"<p>Some of the examples in qlxad are enabled for benchmarking.  That is, the performance of the pricing and sensitivity calculation  is measured, averaged over several iterations, for accurate performance reporting.</p> <p>Further, setting the CMake option <code>QLXAD_DISABLE_AAD</code> to <code>ON</code> builds QuantLib and qlxad with the default <code>double</code> datatype, enabling measurement of the same examples without the overheads involved in using a custom active data type. The benchmark-enabled examples calculate sensitivities using finite differences  in that case,  which also allows verifying correctness of the result against XAD.</p> <p>Bechmark results:</p> Example Sensitivites Valuation run (ms) AAD run (ms) AAD vs Valuation Equity Option Portfolio 98 2.83 7.00 2.47x Barrier Option Replication 13 1.48 4.16 2.81x Swap Portfolio 55 26.05 36.28 1.39x Multicurve Bootstrapping 65 192.11 299.63 1.56x <p>Benchmark configuration:</p> <ul> <li>QuantLib version: 1.30</li> <li>XAD version: 1.2.0</li> <li>XAD configuration: <code>XAD_USE_STRONG_INLINE=ON</code>, <code>XAD_NO_THREADLOCAL=ON</code>, <code>XAD_SIMD_OPTION=AVX512</code></li> <li>OS: Windows Server 2022 Datacenter</li> <li>Compiler: Visual Studio 2022, 17.6.1</li> <li>RAM: 64GB</li> <li>CPU: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz</li> </ul>"},{"location":"quantlib/#getting-help","title":"Getting Help","text":"<p>If you have found an issue, want to report a bug, or have a feature request, please raise a GitHub issue.</p> <p>For general questions about the QuantLib to XAD integration, sharing ideas, engaging with community members, etc, please use GitHub Discussions.</p>"},{"location":"quantlib/#continuous-integration","title":"Continuous Integration","text":"<p>To ensure continued compatibility with QuantLib's master branch, automated CI/CD checks are running in the qlxad repository on a daily basis. Potential breaks (for example do to changes in QuantLib) are therefore detected early and fixed quickly.</p>"},{"location":"ref/areal/","title":"Adjoint Mode Type <code>AReal</code>","text":""},{"location":"ref/areal/#overview","title":"Overview","text":"<pre><code>template &lt;typename T&gt;\nclass AReal : public Expression&lt;T, AReal&lt;T&gt;&gt;\n</code></pre> <p>The class <code>AReal</code> defines an active data type for adjoint mode for the underlying type <code>T</code>, which tracks derivative information on a tape. It is designed to behave exactly like the built-in type <code>double</code>, with all mathematical operations defined for this custom type.</p> <p>Derivatives will only be tracked on tape if the variable has been registered or is dependent on other registered variables. Hence creating and using variables without an active tape is not problematic.</p> <p>See also</p> <p>Tape, Global Functions, AD Mode Interface, Mathematical Operations</p>"},{"location":"ref/areal/#member-functions","title":"Member Functions","text":""},{"location":"ref/areal/#types","title":"Types","text":""},{"location":"ref/areal/#tape_type","title":"<code>tape_type</code>","text":"<p>The type of the tape that is used to store operations on this class.</p>"},{"location":"ref/areal/#slot_type","title":"<code>slot_type</code>","text":"<p>The type used for storing this instance's slot in the tape. This type is useful for checkpointing, where the slot of the inputs and outputs needs to be stored in the checkpoint in order to retrieve or increment their derivatives during adjoint computation.</p>"},{"location":"ref/areal/#value_type","title":"<code>value_type</code>","text":"<p>The value-type of this class, i.e., <code>T</code>.</p>"},{"location":"ref/areal/#constructors-and-destructors","title":"Constructors and Destructors","text":"<pre><code>AReal(const T&amp; val = T())     // (1) construct from value or default-construct\nAReal(const AReal&amp; val)       // (2) copy-constructor\nAReal(AReal&amp;&amp; o)              // (3) move-constructor\nAReal(const Expression&lt;T,Expr&gt;&amp; expr)  // (4) from expression\n~AReal()                      // (5) destructor\n</code></pre> <p>The constructors create new instances of this class.</p> <p>Variant <code>(1)</code> creates a value that is not connected to any tape (it can be registered explicitly using <code>tape.registerInput()</code>).</p> <p>Variants <code>(2)</code> and <code>(3)</code> copy or move from other values, taping the operation if the source type has been registered with a tape.</p> <p>Variant <code>(4)</code> creates a value from an expression template, evaluating the expression and recording the operations on tape if any of the variables on the right-hand side have been registered with a tape. It gets triggered for example by expressions like this:</p> <pre><code>AReal&lt;double&gt; y = x + x*sin(x);\n</code></pre> <p>If <code>x</code> is an instance of <code>AReal&lt;double&gt;</code> itself.</p> <p>The destructor <code>(5)</code> unregisters the variable from the tape if applicable.</p>"},{"location":"ref/areal/#assignments","title":"Assignments","text":"<pre><code>AReal&amp; operator=(const T &amp;val)     // (1) assign from a scalar value\nAReal&amp; operator=(const AReal&amp; val) // (2) copy-assignment\nAReal&amp; operator=(AReal&amp;&amp; val)      // (3) move-assignment\nAReal&amp; operator=(const Expression&lt;T,Expr&gt;&amp; expr)  // (4) from expression\n</code></pre> <p>These assignment operators for <code>AReal</code> behave similar to the equivalent constructors above.</p>"},{"location":"ref/areal/#values-and-derivatives","title":"Values and Derivatives","text":""},{"location":"ref/areal/#getvalue","title":"<code>getValue</code>","text":"<p><code>T getValue() const</code> returns the value as the underlying type (without tape information).</p>"},{"location":"ref/areal/#getderivative","title":"<code>getDerivative</code>","text":"<p><code>T getDerivative() const</code> returns the derivative (adjoint) as stored on the tape (typically after rolling back the operation). It throws an instance of <code>NoTapeException</code> if the variable has not been registered with an active tape.</p>"},{"location":"ref/areal/#setderivative","title":"<code>setDerivative</code>","text":"<p><code>void setDerivative(const T&amp; a)</code> sets the derivative (adjoint) on the tape. Typically this is called in the function outputs after recording the operation, before rolling back the tape.</p>"},{"location":"ref/areal/#setadjoint","title":"<code>setAdjoint</code>","text":"<p>Alias for <code>setDerivative</code>.</p>"},{"location":"ref/areal/#value","title":"<code>value</code>","text":"<p><code>T&amp; value()</code> and <code>const T&amp; value() const</code> return a reference to the underlying passive type value. This can be used to assign a value to the variable without tape recording, as <code>x.value() = 1.2</code>.</p>"},{"location":"ref/areal/#derivative","title":"<code>derivative</code>","text":"<p><code>T&amp; derivative()</code> and <code>const T&amp; derivative() const</code> return a reference to the underlying adjoint value. This can be used to assign a value to the adjoint, as <code>x.derivative() = 1.0</code>, which is equivalent to <code>setDerivative</code>. It can also be used as a replacement for <code>getDerivative</code>.</p>"},{"location":"ref/areal/#shouldrecord","title":"<code>shouldRecord</code>","text":"<p><code>bool shouldRecord() const</code> checks if the variable has been registered with a tape and should therefore be recorded.</p>"},{"location":"ref/areal/#other-operations","title":"Other Operations","text":"<p>In addition, <code>AReal</code> instances support all other mathematical arithmetic operations, such as <code>operator+=</code> and friends. Also, since <code>AReal</code> is an <code>Expression</code>, all math functions defined for expressions also work on instances of this class.</p>"},{"location":"ref/chkpt_cb/","title":"CheckpointCallback","text":"<pre><code>template &lt;typename TapeType&gt; class CheckpointCallback\n</code></pre> <p>Base class of any checkpoint callbacks associated with the given <code>TapeType</code>.</p> <p>User-defined checkpoints should derive from this class and implement <code>computeAdjoints</code> to implement the adjoint computation of the checkpoint. An object of this class should then be registered with the tape using <code>Tape&lt;T&gt;::insertCallback</code>. During computing adjoints, XAD then calls this registered callback once it reaches the corresponding point in the tape.</p> <p>Implementers are responsible to store all needed information for the checkpoint within this class. That is:</p> <ul> <li>The values of input variables,</li> <li>Their slots in the tape,</li> <li>The slots of the output variables on the tape,</li> <li>Any other information that may be needed to propagate the adjoints     of the outputs back to its input variables</li> </ul>"},{"location":"ref/chkpt_cb/#computeadjoint","title":"<code>computeAdjoint</code>","text":"<p><code>virtual void computeAdjoint(TapeType* tape) = 0</code></p> <p>This function is called by XAD during rolling back the tape, giving a reference to itself. Gives weak exception guarantee - if this user-implemented function throws an exception, the tape is in an undefined state and needs to be reset/re-initialized before it can be used again.</p>"},{"location":"ref/complex/","title":"Complex","text":""},{"location":"ref/complex/#overview","title":"Overview","text":"<p>XAD implements specialisations of <code>std::complex</code> for the XAD active data types <code>AReal</code> and <code>FReal</code>. They are are provided in the header <code>XAD/Complex.hpp</code>, along with all the mathematical operations defined in the standard.</p> <p>Note that the complex header is not automatically included with <code>XAD/XAD.hpp</code>. Users must include it as needed.</p>"},{"location":"ref/complex/#stdcomplex-specialisations","title":"<code>std::complex</code> Specialisations","text":"<p>Both <code>std::complex&lt;AReal&lt;T&gt;&gt;</code> and <code>std::complex&lt;FReal&lt;T&gt;&gt;</code> are provided specialisations for the standard complex type (in <code>std</code> namespace), for adjoint and forward modes respectively.</p>"},{"location":"ref/complex/#member-functions","title":"Member Functions","text":"<p>All standard complex member functions are implemented.</p> <p>Below are the non-standard additions and changes of the interface only, using the placeholder <code>XReal&lt;T&gt;</code> as a placeholder inner type, which can be <code>FReal&lt;T&gt;</code> or <code>AReal&lt;T&gt;</code>.</p>"},{"location":"ref/complex/#real","title":"<code>real</code>","text":"<p><code>XReal&lt;T&gt;&amp; complex::real()</code> returns a reference rather than a copy of the real part, to allow for easy access and adjusting of derivatives using <code>derivative()</code>. This applies to both the modifyable and the <code>const</code> versions.</p>"},{"location":"ref/complex/#imag","title":"<code>imag</code>","text":"<p>Returns a reference rather than a copy, for both the modifyable and the <code>const</code> versions.</p>"},{"location":"ref/complex/#setderivative","title":"<code>setDerivative</code>","text":"<p><code>void complex::setDerivative(const T&amp; real_derivative, const T&amp; imag_derivative = T())</code> sets the derivatives (either \\(\\dot{x}\\) or \\(\\bar{x}\\)) for both the real and imaginary parts.</p>"},{"location":"ref/complex/#setadjoint","title":"<code>setAdjoint</code>","text":"<p><code>void complex::setAdjoint(const T&amp; real_derivative, const T&amp; imag_derivative = T())</code> is an alias for <code>setDerivative</code></p>"},{"location":"ref/complex/#getderivative","title":"<code>getDerivative</code>","text":"<p><code>std::complex&lt;T&gt; getDerivative() const</code> gets the derivatives (either \\(\\dot{x}\\) or \\(\\bar{x}\\) for both the real and imaginary parts, represented as a complex of the underlying (<code>double</code>) type.</p>"},{"location":"ref/complex/#getadjoint","title":"<code>getAdjoint</code>","text":"<p><code>std::complex&lt;T&gt; getAdjoint() const</code> is an alias for <code>getDerivative</code></p>"},{"location":"ref/complex/#none-member-functions","title":"None-Member Functions","text":""},{"location":"ref/complex/#derivative","title":"<code>derivative</code>","text":"<pre><code>template &lt;typename T&gt; std::complex&lt;T&gt; derivative(const std::complex&lt;XReal&lt;T&gt; &gt;&amp; z)\n</code></pre> <p>Returns the adjoints of the <code>z</code> variable, represented as a complex number of the underlying double type.</p> <p>Note that since the return type is not a reference, setting derivatives should be done by using the member functions <code>setDerivative</code> or using the <code>real</code> and  <code>imag</code> member functions instead.</p>"},{"location":"ref/complex/#value","title":"<code>value</code>","text":"<pre><code>template &lt;typename T&gt; std::complex&lt;T&gt; value(const std::complex&lt;XReal&lt;T&gt; &gt;&amp; z)\n</code></pre> <p>Returns the value of the <code>z</code> variable (underlying double type), represented as a complex number.</p>"},{"location":"ref/complex/#real_1","title":"<code>real</code>","text":"<pre><code>template &lt;typename T&gt;\nXReal&lt;T&gt;&amp; real(std::complex&lt;XReal&lt;T&gt; &gt;&amp; z)\n</code></pre> <p>Access to the real part by reference.</p>"},{"location":"ref/complex/#imag_1","title":"<code>imag</code>","text":"<pre><code>template &lt;typename T&gt; XReal&lt;T&gt;&amp; imag(std::complex&lt;XReal&lt;T&gt; &gt;&amp; z)\n</code></pre> <p>Access to the imaginary part by reference.</p>"},{"location":"ref/complex/#math-operations","title":"Math Operations","text":"<p>All arithmetic operators and mathematical functions in the C++11 standard have been specialised with the XAD complex data types as well. This also includes the stream read and write operations.</p>"},{"location":"ref/exceptions/","title":"Exceptions","text":"<p>Generally, functions that throw XAD exceptions give mostly the strong guarantee, i.e. the state of the objects involved is unchanged and operations can continue as if the throwing function was not called.</p> <p>Some functions can only give the weak guarantee, i.e., the object is in an undefined state but the application can recover be re-initializing the object. This is notably the case if the user-defined <code>CheckpointCallback::computeAdjoint</code> function throws an exception.</p> <p>XAD defines the following exception types.</p>"},{"location":"ref/exceptions/#xadexception","title":"<code>xad::Exception</code>","text":"<p><code>class Exception : public std::runtime_error</code></p> <p>Base class of all XAD exceptions, including the standard method <code>const char* what() const</code> to return the message of the exception (inherited).</p>"},{"location":"ref/exceptions/#xadtapealreadyactive","title":"<code>xad::TapeAlreadyActive</code>","text":"<p><code>class TapeAlreadyActive : public Exception</code></p> <p>Exception that is thrown when a tape is attempted to be activated while another one is already active for the current thread.</p>"},{"location":"ref/exceptions/#outofrange","title":"<code>OutOfRange</code>","text":"<p><code>class OutOfRange : public Exception</code></p> <p>Exception thrown when an argument is out of the acceptable range.</p>"},{"location":"ref/exceptions/#derivativesnotinitialized","title":"<code>DerivativesNotInitialized</code>","text":"<p><code>DerivativesNotInitialized : public Exception</code></p> <p>Exception thrown if adjoints are attempted to be computed without setting at least one derivative first.</p>"},{"location":"ref/exceptions/#notapeexception","title":"<code>NoTapeException</code>","text":"<p><code>NoTapeException : public Exception</code></p> <p>Exception thrown if a derivative of an <code>AReal</code> object is created without an active tape for the current thread.</p>"},{"location":"ref/expressions/","title":"Expressions","text":""},{"location":"ref/expressions/#expression-template","title":"Expression Template","text":"<pre><code>template &lt;typename T, typename Derived&gt; class Expression\n</code></pre> <p>Represents a mathematical expression in a type. Active data types, such as <code>AReal</code> and <code>FReal</code>, as well as all mathematical expressions inherit from this class. All mathematical operations are defined on this type, rather than any specific derived class.</p> <p>The derived classes are typically created transparently to the user.</p> <p>Note that this class uses the CRTP pattern, where <code>Derived</code> is the derived class itself, so that static polymorphism can be used.</p> <p>All global arithmetic operations defined in C++ are specialized for <code>Expression</code>, so that <code>double</code> or <code>float</code> can be replaced seamlessly with an active data type from XAD. This also includes comparisons.</p> <p>See also</p> <p>Mathematical Operations</p>"},{"location":"ref/expressions/#expression-traits","title":"Expression Traits","text":"<p>XAD also defines expression traits to find information about expressions in a templated context. This is typically only needed when custom functions dealing with the XAD expressions are added.</p>"},{"location":"ref/expressions/#direction-enum","title":"<code>Direction</code> enum","text":"<p>This enum indicates the direction of algorithmic differentiation associated with a type.</p> <pre><code>enum Direction {\nDIR_NONE,       // Not an algorithmic differentiation type\nDIR_FORWARD,    // Forward mode AD type\nDIR_REVERSABLE  // Reverse mode AD type\n};\n</code></pre>"},{"location":"ref/expressions/#exprtraits","title":"<code>ExprTraits</code>","text":"<p>This is the main traits class to get information on an AD type:</p> <pre><code>template &lt;typename T&gt;\nstruct ExprTraits {\nstatic const bool isExpr;      // true if an expression of XAD active type\nstatic const int numVariables; // Number of variables in an expression\nstatic const bool isForward;   // true if forward-mode AD\nstatic const bool isReverse;   // true if reverse-mode AD\nstatic const bool isLiteral;   // true if it's an elementary XAD active type\n// and not an expression\nstatic const Direction direction;  // direction of the expression or type\ntypedef ... nested_type; // underlying type of the expression\n// e.g. double for AReal&lt;double&gt;\ntypedef ... value_type;  // the base active type of a more\n// complex expression template\ntypedef ... scalar_type; // Type when unwrapping a higher order\n// expression, e.g. FReal&lt;double&gt; for\n// an expression of AReal&lt;FReal&lt;double&gt;&gt;\n};\n</code></pre>"},{"location":"ref/freal/","title":"Forward Mode Type <code>FReal</code>","text":""},{"location":"ref/freal/#overview","title":"Overview","text":"<pre><code>template &lt;typename T&gt;\nclass FReal : public Expression&lt;T, FReal&lt;T&gt;&gt;\n</code></pre> <p>The class <code>FReal</code> defines an active data type for forward mode for the underlying type <code>T</code> which tracks derivatives without tape. It is designed to behave exactly like the built-in type <code>double</code>, with all mathematical operations defined for this custom type.</p> <p>It consists of a value and a derivative, both of which are tracked through operations on this class. The derivative of at least one independent variable should be set to 1 before the computation starts to ensure derivative propagation to the outputs.</p> <p>See also</p> <p>Global Functions, AD Mode Interface, Mathematical Operations</p>"},{"location":"ref/freal/#member-functions","title":"Member Functions","text":""},{"location":"ref/freal/#types","title":"Types","text":""},{"location":"ref/freal/#value_type","title":"<code>value_type</code>","text":"<p>The value-type of this class, i.e., <code>T</code>.</p>"},{"location":"ref/freal/#constructors-and-destructors","title":"Constructors and Destructors","text":"<pre><code>FReal(const T&amp; val = T(), const T&amp; der = T()) // (1) construct from value(s)\nFReal(const FReal&amp; val)                // (2) copy-constructor\nFReal(FReal&amp;&amp; o)                       // (3) move-constructor\nFReal(const Expression&lt;T,Expr&gt;&amp; expr)  // (4) from expression\n~FReal()                               // (5) destructor\n</code></pre> <p>The constructors create new instances of this class.</p> <p>Variant <code>(1)</code> creates an instance from a value, as well as optionally sets its derivativ.</p> <p>Variants <code>(2)</code> and <code>(3)</code> copy or move from other values.</p> <p>Variant <code>(4)</code> creates a value from an expression template, evaluating the expression and recording both the result and the derivative of the right hand side expression. It gets triggered for example by expressions like this:</p> <pre><code>FReal&lt;double&gt; y = x + x*sin(x);\n</code></pre> <p>If <code>x</code> is an instance of <code>FReal&lt;double&gt;</code> itself.</p> <p>The destructor <code>(5)</code> destroys the object.</p>"},{"location":"ref/freal/#assignments","title":"Assignments","text":"<pre><code>FReal&amp; operator=(const T &amp;val)     // (1) assign from a scalar value\nFReal&amp; operator=(const FReal&amp; val) // (2) copy-assignment\nFReal&amp; operator=(FReal&amp;&amp; val)      // (3) move-assignment\nFReal&amp; operator=(const Expression&lt;T,Expr&gt;&amp; expr)  // (4) from expression\n</code></pre> <p>These assignment operators for <code>FReal</code> behave similar to the equivalent constructors above.</p>"},{"location":"ref/freal/#values-and-derivatives","title":"Values and Derivatives","text":""},{"location":"ref/freal/#getvalue","title":"<code>getValue</code>","text":"<p><code>T getValue() const</code> returns the value as the underlying type (without tape information).</p>"},{"location":"ref/freal/#getderivative","title":"<code>getDerivative</code>","text":"<p><code>T getDerivative() const</code> returns the derivative.</p>"},{"location":"ref/freal/#setderivative","title":"<code>setDerivative</code>","text":"<p><code>void setDerivative(const T&amp; a)</code> sets the derivative in the object. Typically this is called on independent variables before the operation is started (if not already initialised using the constructor).</p>"},{"location":"ref/freal/#value","title":"<code>value</code>","text":"<p><code>T&amp; value()</code> and <code>const T&amp; value() const</code> return a reference to the underlying passive type value. This can be used to assign a value to the variable without affecting the derivative, as <code>x.value() = 1.2</code>.</p>"},{"location":"ref/freal/#derivative","title":"<code>derivative</code>","text":"<p><code>T&amp; derivative()</code> and <code>const T&amp; derivative() const</code> return a reference to the derivative value. This can be used to assign a value to it as well, as <code>x.derivative() = 1.0</code>, which is equivalent to <code>setDerivative</code>. It can also be used as a replacement for <code>getDerivative</code>.</p>"},{"location":"ref/freal/#other-operations","title":"Other Operations","text":"<p>In addition, <code>FReal</code> instances support all other mathematical arithmetic operations, such as <code>operator+=</code> and friends. Also, since <code>FReal</code> is an <code>Expression</code>, all math functions defined for expressions also work on instances of this class.</p>"},{"location":"ref/global/","title":"Global Functions","text":"<p>This section lists functions that are specific to the active data types and tape management. For mathematical functions, Mathematical Operations.</p>"},{"location":"ref/global/#value","title":"<code>value</code>","text":"<p><code>value(T&amp; x)</code> returns a reference (or const-reference if <code>x</code> is constant) to the value stored in <code>x</code>.</p> <p>If <code>x</code> is a XAD active data type, such as <code>AReal</code> or <code>FReal</code>, this function returns a reference to the stored value (which is assignable).</p> <p>If <code>x</code> is a passive data type, this function simple returns the value itself.</p> <p>This function is especially useful in generic code, as it is defined on any data type.</p>"},{"location":"ref/global/#derivative","title":"<code>derivative</code>","text":"<p><code>derivative(const T&amp; x)</code> returns a reference (or const-reference if <code>x</code> is constant) to the derivative stored in <code>x</code>.</p> <p>If <code>x</code> is a XAD active data type, such as <code>AReal</code> or <code>FReal</code>, this function returns a reference to the stored derivative (which is assignable).</p> <p>If <code>x</code> is a passive data type, this function simply returns 0.</p> <p>This function is especially useful in generic code, as it is defined on any data type.</p>"},{"location":"ref/headers/","title":"Headers and Namespaces","text":"<p>All XAD data types and operations are defined in the <code>xad</code> namespace. For brevity, this namespace has been omitted in the reference section.</p> <p>XAD provides a general header <code>XAD/XAD.hpp</code>, which includes all headers that are commonly needed to work with XAD. Typically, this is all that clients need to include.</p> <p>There are two additional headers provided that can be included on demand:</p> <ul> <li><code>XAD/Complex.hpp</code> - for using complex numbers with XAD data types (see Complex).     This header should be included wherever <code>std::complex</code> is used.</li> <li><code>XAD/StdCompatibility.hpp</code> - This header imports the XAD math functions     into the <code>std</code> namespace, for compatibility reasons.     It enables using constructs like <code>std::sin(x)</code> where <code>x</code> is an XAD type.     Additionally, it also specialises <code>std::numeric_limits</code> for the XAD data types,     so that it provides traits similar to the standard floating point types.</li> </ul>"},{"location":"ref/interface/","title":"AD Mode Interface","text":"<p>XAD provides a set of interface structures that conveniently allow access to the data types needed for different AD modes. These are traits classes with member <code>typedef</code> declarations that allow easy access to mode-specific types.</p> <p>For example, they can be used as:</p> <pre><code>using mode = xad::adj&lt;double&gt;;\nusing adouble = mode::active_type;\n// use active type in functions, etc.\nadouble my_function(adouble x) {...}\nmode::tape_type tape;    // setup tape\n</code></pre>"},{"location":"ref/interface/#mode-interface-classes","title":"Mode Interface Classes","text":""},{"location":"ref/interface/#first-order","title":"First Order","text":""},{"location":"ref/interface/#adjt","title":"<code>adj&lt;T&gt;</code>","text":"<p>Mode interface class for first order adjoint mode, where <code>T</code> is the underlying scalar type (e.g. <code>double</code>).</p>"},{"location":"ref/interface/#fwdt","title":"<code>fwd&lt;T&gt;</code>","text":"<p>Mode interface class for first order forward mode, where <code>T</code> is the underlying scalar type (e.g. <code>double</code>).</p>"},{"location":"ref/interface/#second-order","title":"Second Order","text":""},{"location":"ref/interface/#fwd_adjt","title":"<code>fwd_adj&lt;T&gt;</code>","text":"<p>Mode interface class for second order forward over adjoint mode, where <code>T</code> is the underlying scalar type (e.g. <code>double</code>).</p>"},{"location":"ref/interface/#fwd_fwdt","title":"<code>fwd_fwd&lt;T&gt;</code>","text":"<p>Mode interface class for second order forward over forward mode, where <code>T</code> is the underlying scalar type (e.g. <code>double</code>).</p>"},{"location":"ref/interface/#adj_fwdt","title":"<code>adj_fwd&lt;T&gt;</code>","text":"<p>Mode interface class for second order adjoint over forward mode, where <code>T</code> is the underlying scalar type (e.g. <code>double</code>).</p>"},{"location":"ref/interface/#adj_adjt","title":"<code>adj_adj&lt;T&gt;</code>","text":"<p>Mode interface class for second order adjoint over adjoint mode, where <code>T</code> is the underlying scalar type (e.g. <code>double</code>).</p>"},{"location":"ref/interface/#type-members","title":"Type Members","text":"<p>All mode classes above have type members as described below.</p> <pre><code>template &lt;typename T&gt;\nstruct mode {\ntypedef implementation_defined active_type;   // active data type\ntypedef T                      passive_type;  // fully unwrapped passive type\ntypedef implementation_defined tape_type;     // tape (void for forward mode)\ntypedef passive_type           value_type;    // alias for passive_type\n// for second-order only\ntypedef implementation_defined inner_type;    // first-order active type\n};\n</code></pre>"},{"location":"ref/math/","title":"Mathematical Operations","text":"<p>In the following, the data type <code>T</code> refer to arithmetic data types on which the operation is defined mathematically. This includes the active XAD types as well as the standard passive types.</p> <p>The functions listed here are defined in the <code>xad</code> namespace, and C++ ADL rules (argument-dependent lookup) typically find these functions automatically if they are applied to XAD types. However, for this the calls must be unqualified, i.e. without a namespace specifier.</p> <p>Alternatively, fully qualified names work as usual (e.g. <code>xad::sin(x)</code>), also for <code>float</code> and <code>double</code>.</p> <p>For convenience, if the header <code>XAD/StdCompatibility.hpp</code> is included, the XAD variables are imported into the <code>std</code> namespace, so that existing calls to <code>std::sin</code> and similar functions are working as expected.</p>"},{"location":"ref/math/#absolute-values-max-min-and-rounding","title":"Absolute Values, Max, Min, and Rounding","text":""},{"location":"ref/math/#abs","title":"<code>abs</code>","text":"<p><code>T abs(T x)</code> computes the absolute value of <code>x</code>. Note that for defined second-order derivatives, this computes <code>(x&gt;0)-(x&lt;0)</code></p>"},{"location":"ref/math/#max","title":"<code>max</code>","text":"<p><code>T max(T x, T y)</code> returns the maximum of <code>x</code> and <code>y</code>.</p> <p>Note that for well-defined second order derivative, this is implemented as <code>(x + y + abs(x-y)) / 2</code>.</p>"},{"location":"ref/math/#fmax","title":"<code>fmax</code>","text":"<p><code>T fmax(T x, T y)</code> is synonym for <code>max</code></p>"},{"location":"ref/math/#min","title":"<code>min</code>","text":"<p><code>T min(T x, T y)</code> returns the minimum of <code>x</code> and <code>y</code>. Note that for well-defined second order derivative, this is implemented as <code>(x + y - abs(x-y)) / 2</code>.</p>"},{"location":"ref/math/#fmin","title":"<code>fmin</code>","text":"<p><code>T fmin(T x, T y)</code> is a synonym for <code>min</code>.</p>"},{"location":"ref/math/#floor","title":"<code>floor</code>","text":"<p><code>T floor(T x)</code> rounds towards negative infinity.</p>"},{"location":"ref/math/#ceil","title":"<code>ceil</code>","text":"<p><code>T ceil(T x)</code> rounds towards positive infinity.</p>"},{"location":"ref/math/#trunc","title":"<code>trunc</code>","text":"<p><code>T trunc(T x)</code> rounds towards 0.</p>"},{"location":"ref/math/#round","title":"<code>round</code>","text":"<p><code>T round(T x)</code> rounds to the nearest integer value.</p>"},{"location":"ref/math/#lround","title":"<code>lround</code>","text":"<p><code>long lround(T x)</code> is like <code>round</code>, but converts the result to a <code>long</code> type.</p>"},{"location":"ref/math/#llround","title":"<code>llround</code>","text":"<p><code>long long llround(T x)</code> is like <code>round</code>, but converts the result to a <code>long long</code> type.</p>"},{"location":"ref/math/#fmod","title":"<code>fmod</code>","text":"<p><code>T fmod(T x, T y)</code> returns the floating-point remainder of the division operation <code>x/y</code>, i.e.exactly the value <code>x - n*y</code>, where <code>n</code> is <code>x/y</code> with its fractional part truncated.</p>"},{"location":"ref/math/#remainder","title":"<code>remainder</code>","text":"<p><code>T remainder(T x, T y)</code> calculates the IEEE floating-point remainder of the division operation <code>x/y</code>, i.e. exactly the value <code>x - n*y</code>, where the value <code>n</code> is the integral value nearest the exact value <code>x/y</code>.</p> <p>When <code>abs(n-x/y) = 0.5</code>, the value <code>n</code> is chosen to be even.</p> <p>In contrast to <code>fmod</code>, the returned value is not guaranteed to have the same sign as <code>x</code>.</p>"},{"location":"ref/math/#remquo","title":"<code>remquo</code>","text":"<p><code>T remquo(T x, T y, int* n)</code> is the same as <code>remainder</code>, but returns the integer factor <code>n</code> in addition.</p>"},{"location":"ref/math/#modf","title":"<code>modf</code>","text":"<p><code>T modf(T x, T* iptr)</code> decomposes <code>x</code> into integral and fractional parts, each with the same type and sign as <code>x</code>. The integral part is stored in <code>iptr</code>.</p>"},{"location":"ref/math/#nextafter","title":"<code>nextafter</code>","text":"<p><code>T nextafter(T from, T to)</code> returns the next representable value of <code>from</code> in the direction of <code>to</code>.</p> <p>Mathmatically, the difference of <code>from</code> to the return value is very small. For derivatives, we therefore consider them both the same and calculate derivative accordingly.</p>"},{"location":"ref/math/#copysign","title":"<code>copysign</code>","text":"<p><code>T copysign(T x, T y)</code> copies the sign of the floating point value <code>y</code> to the value <code>x</code>, correctly treating positive/negative zero, NaN, and Inf values. It uses the function <code>signbit</code> internally to determine the sign of <code>y</code>.</p>"},{"location":"ref/math/#trigonometric-functions","title":"Trigonometric Functions","text":""},{"location":"ref/math/#degrees","title":"<code>degrees</code>","text":"<p><code>T degrees(T x)</code> converts the given value in radians to degrees.</p>"},{"location":"ref/math/#radians","title":"<code>radians</code>","text":"<p><code>T radians(T x)</code> converts the given value in degrees to radians.</p>"},{"location":"ref/math/#cos","title":"<code>cos</code>","text":"<p><code>T cos(T x)</code> computes the cosine of <code>x</code>.</p>"},{"location":"ref/math/#sin","title":"<code>sin</code>","text":"<p><code>T sin(T x)</code> computes the sine of <code>x</code>.</p>"},{"location":"ref/math/#tan","title":"<code>tan</code>","text":"<p><code>T tan(T x)</code> computes the tangent of <code>x</code>.</p>"},{"location":"ref/math/#asin","title":"<code>asin</code>","text":"<p><code>T asin(T x)</code> computes the inverse sine of <code>x</code>.</p>"},{"location":"ref/math/#acos","title":"<code>acos</code>","text":"<p><code>T acos(T x)</code> computes the inverse cosine of <code>x</code></p>"},{"location":"ref/math/#atan","title":"<code>atan</code>","text":"<p><code>T atan(T x)</code> computes the inverse tangent of <code>x</code></p>"},{"location":"ref/math/#atan2","title":"<code>atan2</code>","text":"<p><code>T atan2(T x, T y)</code> computes the four-quadrant inverse tangent of a point located at <code>(x, y)</code>.</p>"},{"location":"ref/math/#sinh","title":"<code>sinh</code>","text":"<p><code>T sinh(T x)</code> computes the hyperbolic sine of <code>x</code>.</p>"},{"location":"ref/math/#cosh","title":"<code>cosh</code>","text":"<p><code>T cosh(T x)</code> computes the hyperbolic cosine of <code>x</code>.</p>"},{"location":"ref/math/#tanh","title":"<code>tanh</code>","text":"<p><code>T tanh(T x)</code> computes the hyperbolic tangent of <code>x</code>.</p>"},{"location":"ref/math/#asinh","title":"<code>asinh</code>","text":"<p><code>T asinh(T x)</code> computes the inverse hyperbolic sine of <code>x</code>.</p>"},{"location":"ref/math/#acosh","title":"<code>acosh</code>","text":"<p><code>T acosh(T x)</code> computes the inverse hyperbolic cosine of <code>x</code>.</p>"},{"location":"ref/math/#atanh","title":"<code>atanh</code>","text":"<p><code>T atanh(T x)</code> computes the inverse hyperbolic tangent of <code>x</code>.</p>"},{"location":"ref/math/#powers-exponentials-and-logarithms","title":"Powers, Exponentials, and Logarithms","text":""},{"location":"ref/math/#log","title":"<code>log</code>","text":"<p><code>T log(T x)</code> computes the natural logarithm of <code>x</code>.</p>"},{"location":"ref/math/#log10","title":"<code>log10</code>","text":"<p><code>T log10(T x)</code> computes the base 10 logarithm of <code>x</code>.</p>"},{"location":"ref/math/#log2","title":"<code>log2</code>","text":"<p><code>T log2(T x)</code> computes the base 2 logarithm of <code>x</code>.</p>"},{"location":"ref/math/#exp","title":"<code>exp</code>","text":"<p><code>T exp(T x)</code> computes the exponential of <code>x</code> (base e).</p>"},{"location":"ref/math/#expm1","title":"<code>expm1</code>","text":"<p><code>T expm1(T x)</code> computes <code>exp(x) - 1</code> with higher precision around 0.</p>"},{"location":"ref/math/#exp2","title":"<code>exp2</code>","text":"<p><code>T exp2(T x)</code> computes 2 to the power of <code>x</code>.</p>"},{"location":"ref/math/#log1p","title":"<code>log1p</code>","text":"<p><code>T log1p(T x)</code> cmputes <code>log(1 + x)</code> with higher precision around 0.</p>"},{"location":"ref/math/#sqrt","title":"<code>sqrt</code>","text":"<p><code>T sqrt(T x)</code> computes the square root of <code>x</code>.</p>"},{"location":"ref/math/#cbrt","title":"<code>cbrt</code>","text":"<p><code>T cbrt(T x)</code> computes the cubic root of <code>x</code>.</p>"},{"location":"ref/math/#pow","title":"<code>pow</code>","text":"<p><code>T pow(T x, T y)</code> computes <code>x</code> to the power of <code>y</code>.</p>"},{"location":"ref/math/#ldexp","title":"<code>ldexp</code>","text":"<p><code>T ldexp(T x, int exp)</code> multiplies <code>x</code> by two to the power of <code>exp</code>.</p>"},{"location":"ref/math/#frexp","title":"<code>frexp</code>","text":"<p><code>T frexp(T arg, int* exp)</code> decomposes the given floating point value arg into a normalised fraction and an integral power of two.</p>"},{"location":"ref/math/#ilogb","title":"<code>ilogb</code>","text":"<p><code>int ilogb(T arg)</code> returns the integral part of the logarithm of <code>abs(x)</code>, using <code>FLT_RADIX</code> as base for the log.</p>"},{"location":"ref/math/#scalbn","title":"<code>scalbn</code>","text":"<p><code>T scalbn(T arg, int exp)</code> calculates <code>arg * pow(FLT_RADIX, exp)</code>.</p>"},{"location":"ref/math/#error-functions","title":"Error Functions","text":""},{"location":"ref/math/#erf","title":"<code>erf</code>","text":"<p><code>T erf(T x)</code> computes the error function of <code>x</code>, if provided by the compiler's math library.</p>"},{"location":"ref/math/#erfc","title":"<code>erfc</code>","text":"<p><code>T erfc(T x)</code> computes the complementary error function of <code>x</code>, if provided by the compiler's math library.</p>"},{"location":"ref/math/#floating-point-classification","title":"Floating Point Classification","text":""},{"location":"ref/math/#isinf","title":"<code>isinf</code>","text":"<p><code>bool isinf(T x)</code> checks if value is infinity (positive or negative).</p>"},{"location":"ref/math/#isnan","title":"<code>isnan</code>","text":"<p><code>bool isnan(T x)</code> checks if value is NaN.</p>"},{"location":"ref/math/#isfinite","title":"<code>isfinite</code>","text":"<p><code>bool isfinite(T x)</code> checks if value is finite (not infinite and not NaN).</p>"},{"location":"ref/math/#signbit","title":"<code>signbit</code>","text":"<p><code>bool signbit(T x)</code> returns true if <code>x</code> is negative and false otherwise. Also detects sign bit of zeros.</p>"},{"location":"ref/math/#isnormal","title":"<code>isnormal</code>","text":"<p><code>bool isnormal(T x)</code> checks if the value is a normal floating point number, i.e. not zero, subnormal, infinite, or NaN.</p>"},{"location":"ref/smooth-math/","title":"Smoothed Mathematical Functions","text":"<p>The functions in this section are smoothed equivalents of the original math functions and can be used to allow computing derivatives around discontinuities.</p>"},{"location":"ref/smooth-math/#smooth_abs","title":"<code>smooth_abs</code>","text":"<p><code>T smooth_abs(T x, T c = 0.001)</code> is a smoothed version of <code>abs</code>, defined as:</p> \\[ \\text{smooth\\_abs}(x,c) = \\left\\{\\begin{array}{lll} |x| &amp; &amp; \\text{if }x &lt; c\\text{ or } x &gt; c\\\\[5pt] x^2\\left(\\frac{2}{c}-\\frac{1}{c^2} x\\right) &amp; &amp; \\text{if }0 \\leq x \\leq c\\\\[5pt] x^2\\left(\\frac{2}{c}+\\frac{1}{c^2} x\\right) &amp; &amp; \\text{if }-c \\leq x &lt; 0 \\end{array}\\right. \\] <ul> <li><code>x</code> is the input value</li> <li><code>c</code> is the cut-off point for the spline-approximated area (default: <code>0.001</code>)</li> <li>returns: The smoothed absolute value, defined as above.</li> </ul>"},{"location":"ref/smooth-math/#smooth_max","title":"<code>smooth_max</code>","text":"<p><code>T smooth_max(T x, T y, T c = 0.001)</code> is a smoothed version of <code>max</code>, defined as:</p> \\[ \\text{smooth\\_max}(x,y,c) = 0.5\\left(x+y+\\text{smooth\\_abs}(x-y,c)\\right)  \\] <ul> <li><code>x</code> First argument to max</li> <li><code>y</code> Second argument to max</li> <li><code>c</code> Cut-off point for the spline-approximated area (default: <code>0.001</code>)</li> <li>returns: The smoothed max function, defined as above</li> </ul>"},{"location":"ref/smooth-math/#smooth_min","title":"<code>smooth_min</code>","text":"<p><code>T smooth_min(T x, T y, T c = 0.001)</code> is a smoothed version of <code>min</code>, defined as:</p> \\[ \\text{smooth\\_min}(x,y,c) = 0.5\\left(x+y-\\text{smooth\\_abs}(x-y,c)\\right)  \\] <ul> <li><code>x</code> First argument to min</li> <li><code>y</code> Second argument to min</li> <li><code>c</code> Cut-off point for the spline-approximated area (default: <code>0.001</code>)</li> <li>returns: The smoothed min function, defined as above</li> </ul>"},{"location":"ref/tape/","title":"Tape","text":""},{"location":"ref/tape/#tape_1","title":"<code>Tape</code>","text":"<p><code>template &lt;typename T&gt; class Tape;</code></p> <p>Tape data type to record operations for adjoint computations, using the underlying scalar type <code>T</code> (which may in turn be an active type for higher-order derivative calculations).</p> <p>Typical usage</p> <pre><code>Tape&lt;double&gt; tape;\n// initialize independent variables\nAReal&lt;double&gt; x1 = 1.2, x2 = 12.1;\n// register independents with the tape\ntape.registerInput(x1);\ntape.registerInput(x2);\n// start recording derivatives on tape\ntape.newRecording();\nAReal&lt;double&gt; y = sin(x1) + x1*x2;\n// register output and set adjoint values\ntape.registerOutput(y);\nderivative(y) = 1.0;\n// compute the adjoints of the independent variables\ntape.computeAdjoints();\n// output/use results\nstd::cout &lt;&lt; \"y = \" &lt;&lt; value(y) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx1 = \" &lt;&lt; derivative(x1) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx2 = \" &lt;&lt; derivative(x2) &lt;&lt; \"\\n\";\n</code></pre> <p>For usability, it is recommended to use the type definitions decribed in AD Mode Interfaces instead of using this tape type directly.</p>"},{"location":"ref/tape/#member-typedefs","title":"Member Typedefs","text":""},{"location":"ref/tape/#size_type","title":"<code>size_type</code>","text":"<p>Type for sizes</p>"},{"location":"ref/tape/#slot_type","title":"<code>slot_type</code>","text":"<p>Type used to represent a slot of a specific active variable</p>"},{"location":"ref/tape/#position_type","title":"<code>position_type</code>","text":"<p>Type to represent a position in the tape (same as <code>slot_type</code>)</p>"},{"location":"ref/tape/#active_type","title":"<code>active_type</code>","text":"<p>Active data type that records on this type of tape</p>"},{"location":"ref/tape/#value_type","title":"<code>value_type</code>","text":"<p>The value type of the tape, i.e. <code>T</code></p>"},{"location":"ref/tape/#tape_type","title":"<code>tape_type</code>","text":"<p>The tape's type itself - for generic code</p>"},{"location":"ref/tape/#callback_type","title":"<code>callback_type</code>","text":"<p>The callback type used for checkpoints, i.e. <code>CheckpointCallback&lt;tape_type&gt;*</code></p>"},{"location":"ref/tape/#construct-destruct-and-assign","title":"Construct, Destruct, and Assign","text":"<p>A tape can be created and moved, but it is not copyable.</p> <pre><code>explicit Tape(bool activate = true);   // (1) constructor\nTape(Tape&amp;&amp;);                          // (2) move-constructor\nTape&amp; operator=(Tape&amp;&amp;);               // (3) move-assignment\n~Tape();                               // (4) destructor\n</code></pre> <p>The constructor <code>(1)</code> constructs a new tape, and activates it if needed. If <code>active</code> is <code>true</code>, a global thread-local pointer is set to this constructed instance, resulting all operations and instantiations of active data types that follow to get automatically associated with this tape instance.</p> <p>It may throw <code>TapeAlreadyActive</code>, if <code>activate</code> is true and another tape is already active for the current thread</p> <p>The other constructors facilitate moving a tape, but it cannot be copied.</p>"},{"location":"ref/tape/#recording-control","title":"Recording Control","text":""},{"location":"ref/tape/#activate","title":"<code>activate</code>","text":"<p><code>void activate()</code> sets a global thread-local pointer to this tape instance, resulting all <code>registerInput</code> calls and operations of active data types depending on such inputs to get associated with this tape instance.</p> <p>It may throw <code>TapeAlreadyActive</code> if another tape is already active for the current thread.</p>"},{"location":"ref/tape/#deactivate","title":"<code>deactivate</code>","text":"<p><code>void deactivate()</code> resets the global thread-local pointer to NULL, hence deactivating this tape.</p>"},{"location":"ref/tape/#isactive","title":"<code>isActive</code>","text":"<p><code>bool isActive() const</code> check if the current instance is the currently active tape.</p>"},{"location":"ref/tape/#getactive","title":"<code>getActive</code>","text":"<p><code>static Tape* getActive()</code> get a pointer to the currently active tape, or <code>!c++ nullptr</code> if no active tape has been set.</p> <p>Note that this is a thread-local pointer - calling this function in different threads gives different results.</p>"},{"location":"ref/tape/#registerinput","title":"<code>registerInput</code>","text":"<p><code>void registerInput(active_type&amp; inp)</code> registers the given variable with the tape and start recording dependents of it. A call to this function or its overloads is required in order to calculate adjoints.</p> <p>Other overloads are:</p> <ul> <li><code>void registerInput(std::complex&lt;active_type&gt;&amp; inp)</code> for complex values</li> </ul>"},{"location":"ref/tape/#registerinputs","title":"<code>registerInputs</code>","text":"<p><code>template &lt;typename Inner&gt; void registerInputs(std::vector&lt;Inner&gt;&amp; v)</code> is a convenience function to register all variables in a vector as an input.</p> <p><code>template &lt;typename It&gt; void registerInputs(It first, It last)</code> is a convenience iterator interface to register variables in a range with the tape.</p>"},{"location":"ref/tape/#registeroutput","title":"<code>registerOutput</code>","text":"<p><code>void registerOutput(active_type&amp; inp)</code> registers the given variable as an output with the tape. A call to this function or its overloads is required in order to allow seeding derivatives (adjoints).</p> <p>Other overloads are:</p> <ul> <li><code>void registerOutput(std::complex&lt;active_type&gt;&amp; inp)</code> registers a complex-valued output.</li> </ul>"},{"location":"ref/tape/#registeroutputs","title":"<code>registerOutputs</code>","text":"<p><code>template &lt;typename Inner&gt; void registerOutputs(std::vector&lt;Inner&gt;&amp; v)</code> is a convenience function to register all variables in a vector as an input.</p> <p><code>template &lt;typename It&gt; void registerOutputs(It first, It last)</code> is a convenience iterator interface to register variables in a range with the tape.</p>"},{"location":"ref/tape/#newrecording","title":"<code>newRecording</code>","text":"<p><code>void newRecording()</code> starts recording derivatives.</p> <p>This function should be called after the independent variables are initialized and registered, as the <code>computeAdjoints</code> method will roll back the adjoints until the point where <code>newRecording</code> was called.</p>"},{"location":"ref/tape/#computeadjoints","title":"<code>computeAdjoints</code>","text":"<p><code>void computeAdjoints()</code> propagates adjoints by interpreting the operations on the tape.</p> <p>This function should be called after the output derivatives (adjoints) have been initialized to a non-zero value.</p> <p>After this call, the derivatives of the independent variables are set and can be obtained.</p> <p>It throws <code>DerivativesNotInitialized</code> if called without setting any derivative first.</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p>"},{"location":"ref/tape/#getposition","title":"<code>getPosition</code>","text":"<p><code>position_type getPosition()</code> returns the current position in the tape as an opaque integer (its value is internal and should not be relied upon in client code). This posiiton can later be used in the methods <code>clearDerivativesAfter</code>, <code>resetTo</code>, and <code>computeAdjointsTo</code>.</p>"},{"location":"ref/tape/#clearderivativesafter","title":"<code>clearDerivativesAfter</code>","text":"<p><code>void clearDerivativesAfter(position_type pos)</code> clears all derivatives after the given position in the tape (resets them to zero). Derivatives before this point keep their value, meaning that further calls to <code>computeAdjoints</code> will potentially increment these adjoints further.</p>"},{"location":"ref/tape/#resetto","title":"<code>resetTo</code>","text":"<p><code>void resetTo(position_type pos)</code> resets the tape back to the given position. All statements recorded after this point will be discarded.</p> <p>Warning</p> <p>If variables registered after the given postion (i.e. dependent variables computed after this position) are used again after a call to <code>resetTo</code>,  the behaviour is undefined, as their slot in the tape is no longer valid.</p>"},{"location":"ref/tape/#computeadjointsto","title":"<code>computeAdjointsTo</code>","text":"<p><code>void computeAdjointsTo(position_type pos)</code> works like <code>computeAdjoints</code>, but stops rolling back the adjoints at the given position in the tape.</p>"},{"location":"ref/tape/#clearall","title":"<code>clearAll</code>","text":"<p><code>void clearAll()</code> clears the stored tape info and brings it back to its initial state.</p> <p>While this clears the content, it leaves allocated memory untouched. This may be a performance gain compared to repeated construction/destruction of tapes of the same time, for example in a path-wise AD Monte-Carlo.</p>"},{"location":"ref/tape/#derivatives","title":"Derivatives","text":""},{"location":"ref/tape/#derivative","title":"<code>derivative</code>","text":"<p><code>T&amp; derivative(slot_type s)</code> gets a reference to the derivative associated with the slot <code>s</code>.</p> <p>It throws <code>OutOfRange</code> if the given slot is not associated with a stored derivative. (Note that it is only thrown in debug mode for performance reasons, otherwise the behaviour is undefined in this case)</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p> <p>The const version <code>const T&amp; derivative(slot_type s) const</code> gets a const reference to the derivative associated with the slot <code>s</code> and otherwise behaves the same.</p>"},{"location":"ref/tape/#getderivative","title":"<code>getDerivative</code>","text":"<p><code>T getDerivative(slot_type s) const</code> gets a copy of the value of the derivative associated with the slot <code>s</code>.</p> <p>It throws <code>OutOfRange</code> if the given slot is not associated with a stored derivative. (Note that it is only thrown in debug mode for performance reasons, otherwise the behaviour is undefined in this case)</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p>"},{"location":"ref/tape/#setderivative","title":"<code>setDerivative</code>","text":"<p><code>void setDerivative(slot_type s, const T&amp; v)</code> sets the value of the derivative associated with the slot <code>s</code> to <code>v</code>.</p> <p>It throws <code>OutOfRange</code> if the given slot is not associated with a stored derivative. (Note that it is only thrown in debug mode for performance reasons, otherwise the behaviour is undefined in this case)</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p>"},{"location":"ref/tape/#clearderivatives","title":"<code>clearDerivatives</code>","text":"<p><code>void clearDerivatives()</code> resets all stored derivatives to 0 (but leaving the recorded data in place). This can be used to calculate derivatives w.r.t. multiple outputs, as the same tape can be rolled back multiple times.</p>"},{"location":"ref/tape/#status","title":"Status","text":""},{"location":"ref/tape/#printstatus","title":"<code>printStatus</code>","text":"<p><code>void printStatus() const</code> prints the number of recorded operations, statements, and registered variables to stdout.</p>"},{"location":"ref/tape/#getmemory","title":"<code>getMemory</code>","text":"<p><code>std::size_t getMemory() const</code> returns the memory in bytes that is occupied by the tape.</p>"},{"location":"ref/tape/#checkpointing","title":"Checkpointing","text":""},{"location":"ref/tape/#insertcallback","title":"<code>insertCallback</code>","text":"<p><code>void insertCallback(callback_type cb)</code> inserts a checkpoint callback into the tape.</p> <p>During computing adjoints (<code>computeAdjoints</code>), this callback is called when the tape reaches the current position, allowing users to implement their own adjoint computation.</p> <p>Note that the parameter is provided by pointer (<code>callback_type</code> is a pointer), but the tape does not take ownership. It is the responsibility of the user to free the memory for the callback object. Alternatively, the Checkpoint Callback Memory Management API can be used to have the tape destroy the callbacks automatically.</p>"},{"location":"ref/tape/#getandresetoutputadjoint","title":"<code>getAndResetOutputAdjoint</code>","text":"<p><code>T getAndResetOutputAdjoint(slot_type slot)</code> obtains the output adjoint stored in <code>slot</code>and resets it to 0.</p> <p>This function should be called by <code>CheckpointCallback&lt;TapeType&gt;::computeAdjoints</code> to get the current value of the adjoint. It also resets its adjoint to 0 on the tape to allow re-use of that variable.</p> <p>It throws <code>OutOfRange</code> if the given slot is not associated with a stored derivative. (Note that it is only thrown in debug mode, otherwise the behaviour is undefined)</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p>"},{"location":"ref/tape/#incrementadjoint","title":"<code>incrementAdjoint</code>","text":"<p><code>void incrementAdjoint(slot_type slot, const T&amp; x)</code> increments the adjoint of the given slot by the value <code>x</code>.</p> <p>This function should be called at the end of a <code>CheckpointCallback&lt;TapeType&gt;::computeAdjoints</code> implementation, to update the input adjoints with the computed adjoint increments.</p> <p>It throws <code>OutOfRange</code> if the given slot is not associated with a stored derivative. (Note that it is only thrown in debug mode, otherwise the behaviour is undefined)</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p>"},{"location":"ref/tape/#newnestedrecording","title":"<code>newNestedRecording</code>","text":"<p><code>void newNestedRecording()</code> starts a new nested recording that can be rolled-back on its own. It must be ended with <code>endNestedRecording</code>.</p> <p>It is intended for use within a <code>CheckpointCallback&lt;TapeType&gt;::computeAdjoints</code> implementation, when from a checkpoint, the adjoints are computed using XAD in a nested recording.</p> <p>To avoid forgetting the call to <code>endNestedRecording</code>, consider using the RAII class <code>ScopedNestedRecording</code>.</p>"},{"location":"ref/tape/#endnestedrecording","title":"<code>endNestedRecording</code>","text":"<p><code>void endNestedRecording()</code> ends a nested recording.</p>"},{"location":"ref/tape/#checkpoint-callback-memory-management","title":"Checkpoint Callback Memory Management","text":""},{"location":"ref/tape/#pushcallback","title":"<code>pushCallback</code>","text":"<p><code>void pushCallback(callback_type cb)</code> lets this tape handle the de-allocation of the given callback, destroying the dynamically-allocated <code>cb</code>.</p> <p>When the tape is destructed, it also destructs all callbacks that have been registered using this function.</p> <p>Use this if checkpoints are created in a stateless function to avoid having to track and destroy checkpoint callbacks manually.</p>"},{"location":"ref/tape/#getlastcallback","title":"<code>getLastCallback</code>","text":"<p><code>callback_type getLastCallback()</code> obtains the last <code>CheckpointCallback</code> object that has been pushed with <code>pushCallback</code>.</p> <p>This can be useful if multiple subsequent checkpoints can be added to the same checkpoint callback object.</p> <p>Throws <code>OutOfRange</code>: if the callback stack is empty.</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p>"},{"location":"ref/tape/#getnumcallbacks","title":"<code>getNumCallbacks</code>","text":"<p><code>size_type getNumCallbacks() const</code> gets the number of callback objects that have been pushed by <code>pushCallback</code>.</p>"},{"location":"ref/tape/#havecallbacks","title":"<code>haveCallbacks</code>","text":"<p><code>bool haveCallbacks() const</code> checks if there have been any checkpoint callbacks registered by <code>pushCallback</code>.</p>"},{"location":"ref/tape/#popcallback","title":"<code>popCallback</code>","text":"<p><code>void popCallback()</code> removes the callback object that has been last pushed by <code>pushCallback</code>. It throws <code>OutOfRange</code> if the stack of callbacks is empty</p> <p>Gives strong exception safety guarantee - tape state unchanged in case of exception.</p>"},{"location":"ref/tape/#scopednestedrecording","title":"<code>ScopedNestedRecording</code>","text":"<pre><code>template &lt;typename TapeType&gt; class ScopedNestedRecording\n</code></pre> <p>Convenience RAII class to ensure that a call to <code>Tape&lt;T&gt;::newNestedRecording</code> is always followed by the corresponding <code>Tape&lt;T&gt;::endNestedRecording</code>.</p> <p>It should be constructed on the stack. On creation it starts a nested recording on the corresponding tape, and on destruction it ends the nested recording. This is useful for checkpoint callbacks, i.e. within the implementation of <code>CheckpointCallback&lt;TapeType&gt;::computeAdjoints</code>.</p>"},{"location":"ref/tape/#construct-and-destruct","title":"Construct and Destruct","text":"<pre><code>ScopedNestedRecording(TapeType* t);\n~ScopedNestedRecording();\n</code></pre> <p>The constructor starts a new nested recording on the given tape and track it with this object. It calls <code>newNestedRecording</code> on the given tape.</p> <p>The destructor calles <code>endNestedRecording</code> on the given tape automatically.</p>"},{"location":"ref/tape/#member-functions","title":"Member Functions","text":""},{"location":"ref/tape/#computeadjoints_1","title":"<code>computeAdjoints</code>","text":"<p><code>void computeAdjoints()</code> computes adjoints within the nested recording.</p>"},{"location":"ref/tape/#incrementadjoint_1","title":"<code>incrementAdjoint</code>","text":"<p><code>void incrementAdjoint(TapeType::slot_type slot, const TapeType::value_type&amp; value)</code> increments the adjoint given by the slot by the given value, similar to <code>Tape&lt;T&gt;::incrementAdjoint</code>.</p>"},{"location":"ref/tape/#gettape","title":"<code>getTape</code>","text":"<p><code>TapeType* getTape()</code> returns the underlying tape for this nested recording.</p>"},{"location":"ref/version/","title":"Version Information","text":"<p>The XAD version can be queried through a set of preprocessor macros, described in the following.</p> Macro Description <code>XAD_VERSION_MAJOR</code> Numeric value of the XAD major version number, i.e. <code>1</code> for <code>1.x.y</code>. <code>XAD_VERSION_MINOR</code> Numeric value of the XAD minor version number, i.e. <code>4</code> for <code>x.4.y</code>. <code>XAD_VERSION_PATCH</code> Numeric value of the XAD path version number, up to the first non-numeric character. Thus, for <code>1.0.0rc1</code>, the value of this macro is <code>0</code>. <code>XAD_VERSION_PATCHSTRING</code> String representation of the XAD patch version number, including non-numeric suffixes. <code>XAD_VERSION</code> Numeric representation of the full XAD Version number (without non-numeric suffixes e.g. for release candiates and betas). It is computed as:     <code>XAD_VERSION = XAD_MAJOR * 10000 + XAD_MINOR * 100 + XAD_PATCH</code> <code>XAD_VERSION_STRING</code> String representation of the full XAD version, including non-numeric suffixes, e.g. <code>1.1.0rc1</code>"},{"location":"tutorials/basic/","title":"Basic Usage","text":"<p>In this section, we will illustrate how to use XAD to compute first order derivatives in both forward and adjoint mode.</p> <p>As an example, we choose a simple function with 4 inputs and 1 output variable, defined as:</p> <pre><code>double f(double x0, double x1, double x2, double x3)\n{\ndouble a = sin(x0) * cos(x1);\ndouble b = x2 * x3 - tan(x1 - x2);\ndouble c = a + 2* c;\nreturn c*c;\n}\n</code></pre> <p>We will compute derivatives of this function at the point:</p> <pre><code>double x0 = 1.0;\ndouble x1 = 1.5;\ndouble x2 = 1.3;\ndouble x3 = 1.2;\n</code></pre>"},{"location":"tutorials/basic/#prerequisite-replace-active-variables","title":"Prerequisite: Replace Active Variables","text":"<p>In order to use XAD to differentiate this function, we first must replace all independent data types and all values that depend on them with an active data type provided by XAD. In the above function, all variables depend on the inputs and thus all occurrences of <code>double</code> must be replaced.</p> <p>This can be done in one of two ways:</p> <ol> <li>The variables can be replaced directly, given the desired mode of differentiation.     For example, for forward mode <code>double</code> is replaced by the type     <code>FReal</code> and for adjoint mode the type <code>AReal</code>.</li> <li>The function is made a template, so that it can be called with any data type,     including the original <code>double</code>.</li> </ol> <p>We choose the second approach for this tutorial, thus the function becomes:</p> <pre><code>template &lt;class T&gt;\nT f(T x0, T x1, T x2, T x3)\n{\nT a = sin(x0) * cos(x1);\nT b = x2 * x3 - tan(x1 - x2);\nT c = a + 2* b;\nreturn c*c;\n}\n</code></pre> <p>This means we can use the same definition with both forward and adjoint modes.</p>"},{"location":"tutorials/basic/#forward-mode","title":"Forward Mode","text":"<p>As illustrated in Algorithmic Differentiation Background: Forward Mode, when applied to a function with a single output, the forward mode of algorithmic differentiation can compute one derivative at a time. For illustration, we choose to derive the function with respect to the input variable <code>x0</code>.</p> <p>To initiate the forward mode, we must first declare active variables with the appropriate type. XAD provides convenience typedefs to select the mode of differentiation, illustrated in detail in AD Mode Interface. For forward mode, we can declare the types needed as:</p> <pre><code>typedef xad::fwd&lt;double&gt; mode;\ntypedef mode::active_type AD;\n</code></pre> <p>We can then use the <code>AD</code> typedef for our variables.</p> <p>The next step is to initialize the dependent variables, which is simply done by assigning the input values to new variables of type <code>AD</code>:</p> <pre><code>AD x0_ad = x0;\nAD x1_ad = x1;\nAD x2_ad = x2;\nAD x3_ad = x3;\n</code></pre> <p>For forward mode, we must now seed the initial derivative for the variable we are interested in with the value 1 (as described in Algorithmic Differentiation Background: Forward Mode), as:</p> <pre><code>derivative(x0_ad) = 1.0;\n</code></pre> <p>The global function <code>derivative</code> is a convenience function that works on any active data type. Alternatively, we could have used the member function <code>FReal::setDerivative</code>.</p> <p>At this point we are ready to call our function and it will compute the function value as well as the derivative we are interested in:</p> <pre><code>AD y = f(x0_ad, x1_ad, x2_ad, x3_ad);\n</code></pre> <p>We can now access the results using the <code>value</code> and <code>derivative</code> functions on the output (or the member functions <code>FReal::getDerivative</code> and <code>FReal::getValue</code>). For example, the following code outputs them to the console:</p> <pre><code>std::cout &lt;&lt; \"y = \" &lt;&lt; value(y) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx0 = \" &lt;&lt; derivative(y) &lt;&lt; \"\\n\";\n</code></pre> <p>See also</p> <p>This example is included with XAD (<code>fwd_1st</code>).</p>"},{"location":"tutorials/basic/#adjoint-mode","title":"Adjoint Mode","text":"<p>The adjoint mode of automatic differentiation is the natural choice for the function at hand, as it has a single output and multiple inputs. We can get all four derivatives in one execution.</p> <p>Adjoint mode needs a tape to record the operations and their values during the valuation. After setting the adjoints of the outputs, this tape can then be rolled back to compute the adjoints of the inputs.</p> <p>Both the active data type and the tape type can be obtained from the interface structure <code>adj</code>:</p> <pre><code>typedef xad::adj&lt;double&gt; mode;\ntypedef mode::tape_type tape_type;\ntypedef mode::active_type AD;\n</code></pre> <p>The first step for computing adjoints is to initialise the tape::</p> <pre><code>tape_type tape;\n</code></pre> <p>This calls the default constructor <code>Tape::Tape</code>, which creates the tape and activates it.</p> <p>Next, we create the input variables and register them with the tape:</p> <pre><code>AD x0_ad = x0;\nAD x1_ad = x1;\nAD x2_ad = x2;\nAD x3_ad = x3;\ntape.registerInput(x0);\ntape.registerInput(x1);\ntape.registerInput(x2);\ntape.registerInput(x3);\n</code></pre> <p>Note that only variables registered as inputs with the tape and all variables dependent on them are recorded. Also note that before registering active variables, the current threads needs to have an active tape. To ensure thread-safety, every thread of the application can have its own active tape.</p> <p>Once the independent variables are set, we can start recording derivatives on tape and run the algorithm:</p> <pre><code>tape.newRecording();\nAD y = f(x0_ad, x1_ad, x2_ad, x3_ad);\n</code></pre> <p>At this stage, we have all operations recorded and have the value computed. We now need to register the outputs with the tape as well, before we can seed the initial adjoint of the output wit 1 as explained in Algorithmic Differentiation Background: Adjoint Mode:</p> <pre><code>tape.registerOutput(y);\nderivative(y) = 1.0;\n</code></pre> <p>This uses the global function <code>derivative</code>, which returns a reference to the stored derivative (or adjoint) of the given parameter. Alternatively the member functions <code>AReal::setAdjoint</code> or <code>AReal::setDerivative</code> can be used for the same purpose.</p> <p>What is left is interpreting the tape to compute the adjoints of the independent variables:</p> <pre><code>tape.computeAdjoints();\n</code></pre> <p>We can now access the adjoints of the inputs, which are the derivatives we are interested in, via the global <code>derivative</code> function or the member function <code>AReal::getDerivative</code>:</p> <pre><code>std::cout &lt;&lt; \"y     = \" &lt;&lt; value(y) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx0 = \" &lt;&lt; derivative(x0_ad) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx1 = \" &lt;&lt; derivative(x1_ad) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx2 = \" &lt;&lt; derivative(x2_ad) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx3 = \" &lt;&lt; derivative(x3_ad) &lt;&lt; \"\\n\";\n</code></pre> <p>See also</p> <p>This example is included with XAD (<code>adj_1st</code>).</p>"},{"location":"tutorials/basic/#best-practices","title":"Best Practices","text":"<p>When the algorithm to be evaluated has less outputs than inputs, adjoint mode should be preferred. However, when only a small number of derivatives are needed (e.g. less than 5), the memory for the tape can be avoided by using forward mode. Experimentation is advised to find the optimal mode for the given algorithm.</p>"},{"location":"tutorials/checkpointing/","title":"Checkpointing","text":"<p>Checkpointing is a technique to reduce the memory footprint of the tape in adjoint mode algorithmic differentiation. Instead of recording the full algorithm on tape, which can quickly result in gigabytes of memory in a large computation, the tape is recorded for specific stages of the algorithm, one at a time. This is illustrated in the following figure:</p> <p></p> <p>The algorithm is divided into stages, where the input data of each stage is stored in a checkpoint and the outputs are computed passively (without recording on tape). Once the final output of the algorithm is computed, the adjoint of the output is initialized and at each checkpoint during tape rollback:</p> <ol> <li>The inputs to the checkpoint are loaded,</li> <li>The operations of this stage only are recorded on tape,</li> <li>The output adjoints of this stage are initialized,</li> <li>The tape is rolled back for this stage, computing the adjoints of the stage inputs,</li> <li>The input adjoints are incremented by these values, and</li> <li>The tape is wiped before proceeding with the previous stage.</li> </ol> <p>Using this method, the tape memory is limited by the amount needed to record one algorithm stage instead of the full algorithm. However, each forward computation is computed twice, hence checkpointing trades computation for memory.</p> <p>In practice, as using less memory leads to higher cache-efficiency, checkpointing may be faster overall than recording the full algorithm even though more computations are performed.</p>"},{"location":"tutorials/checkpointing/#example-algorithm","title":"Example Algorithm","text":"<p>To demonstrate the checkpointing method, we choose a simple repeated application of the sine function to a single input:</p> <pre><code>template &lt;class T&gt;\nvoid repeated_sin(int n, T&amp; x)\n{\nfor (int i = 0; i &lt; n; ++i)\nx = sin(x);\n}\n</code></pre> <p>We divide the for loop into equidistant stages and insert a checkpoint at each of these.</p>"},{"location":"tutorials/checkpointing/#checkpoint-callback","title":"Checkpoint Callback","text":"<p>To create a checkpoint, we need to store the inputs of the stage and the slots in the tape for the inputs and outputs in a callback object inheriting from <code>CheckpointCallback</code>. The virtual method <code>CheckpointCallback::computeAdjoint</code> needs to be overridden to perform the per-stage adjoint computation. As all stages are identical, we choose to implement the functionality of all checkpoints within a single callback object and store the required inputs in a stack data structure. Alternatively we could have created a new checkpoint callback object at every checkpoint. The prototype for our callback is:</p> <pre><code>template &lt;class Tape&gt;\nclass SinCheckpointCallback : public xad::CheckpointCallback&lt;Tape&gt;\n{\npublic:\ntypedef typename Tape::slot_type   slot_type;   // type for slot in the tape\ntypedef typename Tape::value_type  value_type;  // double\ntypedef typename Tape::active_type active_type; // AReal&lt;double&gt;\nactive_type computeStage(int n, active_type&amp; x); // forward computation\nvoid computeAdjoint(Tape* tape) override;        // adjoint computation\nprivate:\nstd::stack&lt;int&gt; n_;                    // number of iterations in this stage\nstd::stack&lt;value_type&gt; x_;             // input values for this stage\nstd::stack&lt;slot_type&gt; slots_;          // tape slots for input and output\n};\n</code></pre> <p>For convenience of implementation, we added the forward computation for one stage within the same class in the <code>computeStage</code> method, which could also be performed outside of the object.</p>"},{"location":"tutorials/checkpointing/#computestage-method","title":"<code>computeStage</code> Method","text":"<p>Within the <code>computeStage</code> method, we first store the input value, the number of iterations, and the slots of the input in the checkpoint object:</p> <pre><code>n_.push(n);\nslots_.push(x.getSlot());\nvalue_type x_p = value(x);\nx_.push(x_p);\n</code></pre> <p>We then compute the stage with the passive variable (not recording on the tape):</p> <pre><code>repeated_sin(n, x_p);\n</code></pre> <p>The value of the output active variable needs to be updated with the result and we need to store the slot of the output variable in the checkpoint also:</p> <pre><code>value(x) = x_p;\nslots_.push(x.getSlot());\n</code></pre> <p>Note that we did not need to register <code>x</code> as an output with the tape here, as we had to do with the external functions example before, since the variable is already registered on tape (it's both input and output).</p> <p>What is left is to register this callback object with the tape so that its <code>computeAdjoint</code> method is called at this point when the tape is rolled back:</p> <pre><code>Tape::getActive()-&gt;insertCallback(this);\n</code></pre>"},{"location":"tutorials/checkpointing/#computeadjoint-method","title":"<code>computeAdjoint</code> Method","text":"<p>The <code>computeAdjoint</code> method is called automatically by XAD at the checkpoints in the tape. We first need to load the inputs to this computation stage and obtain the adjoint of the output:</p> <pre><code>slot_type outputidx = slots_.top();  slots_.pop();\nslot_type inputidx = slots_.top();   slots_.pop();\nint n = n_.top();                    n_.pop();\nvalue_type outputadj = tape-&gt;getAndResetOutputAdjoint(outputslot);\n</code></pre> <p>The function <code>Tape::getAndResetOutputAdjoint</code> reads the adjoint corresponding to the slot given and resets it to 0. This reset is generally required as the variable corresponding to the slot may be re-used (overwritten) in the algorithm, as is the case in the <code>repeated_sin</code> function.</p> <p>We now want to use XAD to compute the adjoints just for this computation stage. This is performed by creating a nested recording within the global tape, than can be rolled back individually:</p> <pre><code>active_type x = x_.top();               // local independent variable\nx_.pop();\ntape-&gt;registerInput(x);                 // need to register to record\nxad::ScopedNestedRecording&lt;Tape&gt; nested(tape);  // nested recording\nrepeated_sin(n, x_ad);                  // run actively\ntape-&gt;registerOutput(x);                // register x as an output\nderivative(x) = output_adj;             // set output adjoint\nnested.computeAdjoints();               // rollback nested tape\nnested.incrementAdjoint(inputslot, derivative(x));  // incr. input adjoint\n</code></pre> <p>In a similar fashion to simple adjoint mode (see Basic Usage), we first initialize the local independent variables as active data types and start a nested recording. This is performed by creating a local object <code>nested</code> of type <code>ScopedNestedRecording</code>, which wraps calls to <code>Tape::newNestedRecording</code> in its constructor and <code>Tape::endNestedRecording</code> in its destructor. It is recommended to use the <code>ScopedNestedRecording</code> for this purpose to make sure the nested recording is always finished when the scope is left.</p> <p>Next we record the operations for this stage by running the algorithm actively. We then set the adjoint of the output and compute the adjoints of the inputs. The adjoints of the inputs to this stage can then be incremented.</p> <p>Note that when the <code>nested</code> object goes out of scope, i.e. when its destructor is called, the nested tape for this computation stage is wiped and the memory can be reused for the previous stage. This saves overall memory.</p>"},{"location":"tutorials/checkpointing/#call-site","title":"Call-Site","text":"<p>The full algorithm with checkpointing can then be initiated as follows:</p> <pre><code>tape_type tape;\nAD x_ad = x;                             // initialized indepedent variables\ntape.registerInput(x_ad);                // register with the tape\ntape.newRecording();                     // start recording derivatives\nSinCheckpointCallback&lt;tape_type&gt; chkpt;  // setup checkpointing object\nint checkpt_distance = 4;                // we checkpoint every 4 iterations\nfor (int i = 0; i &lt; n; i += checkpt_distance)\n{\nint m = min(checkpt_distance, n-i);\nchkpt.computeStage(m, x_ad);             // one computation stage\n}\ntape.registerOutput(x_ad);\nderivative(x_ad) = 1.0;\ntape.computeAdjoints();\nstd::cout &lt;&lt; \"xout       = \" &lt;&lt; value(x_ad) &lt;&lt; \"\\n\"\n&lt;&lt; \"dxout/dxin = \" &lt;&lt; derivative(x_ad) &lt;&lt; \"\\n\";\n</code></pre> <p>This follows largely the same procedure as given in Basic Usage, but setting up the checkpoint object and calling its <code>computeStage</code> member for every stage of the algorithm (4 iterations in this example).</p> <p>Note</p> <p>It is important that the checkpoint callback object is valid when <code>Tape::computeAdjoints</code> is called.  It should not be destroyed before.</p> <p>See Checkpoint Callback Memory Management  for how to use tape-based destruction with dynamically allocated checkpoint callbacks.</p> <p>See also</p> <p>This example is included with XAD (<code>checkpointing</code>).</p>"},{"location":"tutorials/checkpointing/#other-usage-patterns","title":"Other Usage Patterns","text":"<p>Alternative methods may be used to update the adjoints within a checkpoint's <code>CheckpointCallback::computeAdjoint</code> method, such as:</p> <ul> <li>Forward mode algorithmic differentiation within an outer adjoint mode</li> <li>Finite differences (bumping)</li> <li>Analytic derivatives</li> <li>External library functions (see External Functions)</li> </ul> <p>Checkpointing can also be used recursively, i.e., new checkpoints are created within a nested tape in a checkpoint.</p> <p>The benefits of each of these approaches are highly application-dependent.</p>"},{"location":"tutorials/external_functions/","title":"External Functions","text":"<p>Often parts of the algorithm to be differentiated are not available in source code. For example, a routine from an external math library may be called. Reimplementing it may not be desirable (for performance or development effort reasons), in which case the derivatives of this function need to be implemented manually in some form.</p> <p>This can be achieved by either:</p> <ul> <li>Applying finite differences to the library function (bumping),</li> <li>Implementing the adjoint code of the function by hand, or</li> <li>Computing the derivatives analytically, possibly using other library functions.</li> </ul> <p>In these cases, the external function interface of XAD can be used to integrate the manual derivatives, which is described below. With the same technique, performance- or memory-critical parts of the application may be hand-tuned.</p>"},{"location":"tutorials/external_functions/#example-algorithm","title":"Example Algorithm","text":"<p>We pick an example algorithm which computes the length of a multi dimensional vector. This is defined as:</p> \\[ y = \\sqrt{\\sum_0^{N-1} x_i^2} \\] <p>The goal is to compute the derivatives of \\(y\\) with respect to all input vector elements using adjoint mode.</p> <p>The algorithm can be implemented in C++ code as:</p> <pre><code>std::vector&lt;double&gt; xsqr(n);\nfor (int i = 0; i &lt; n; ++i)\nxsqr[i] = x[i] * x[i];\ndouble y = sqrt(sum_elements(x, n));\n</code></pre> <p>For this example, we assume that the <code>sum_elements</code> is an external function implemented in a library that we do not have source code of. It has the prototype:</p> <pre><code>double sum_elements(const double* x, int n);\n</code></pre>"},{"location":"tutorials/external_functions/#external-function-for-adjoint-mode","title":"External Function For Adjoint Mode","text":"<p>To use the external function, we follow this procedure:</p> <ol> <li>At the point of the call, convert the values of the input active variables     to the underlying plain data type (<code>double</code>)</li> <li>Call the external function passively</li> <li>Assign the result values to active output variables so the tape recording     can continue</li> <li>Store the tape slots of the inputs and outputs with a checkpoint callback object     and register it with the tape.</li> <li>When computing adjoints, this callback needs to load the adjoint of the outputs,     propagate to them to the inputs manually,     and increment the input adjoints by these values.</li> </ol> <p>We put all the functionality into a callback object. We derive from the <code>CheckpointCallback</code> base class and implement at least the virtual method <code>CheckpointCallback::computeAdjoint</code>. This method gets called during tape rollback. We also place the forward computation within the same object (this could also be done outside of the callback class). The declaration of our callback class looks like this:</p> <pre><code>template &lt;class Tape&gt;\nclass ExternalSumElementsCallback : public xad::CheckpointCallback&lt;Tape&gt;\n{\npublic:\ntypedef typename Tape::slot_type   slot_type;   // type for slot in the tape\ntypedef typename Tape::value_type  value_type;  // double\ntypedef typename Tape::active_type active_type; // AReal&lt;double&gt;\nactive_type computeExternal(const active_type* x, int n); // forward compute\nvoid computeAdjoint(Tape* tape) override;                 // adjoint compute\nprivate:\nstd::vector&lt;slot_type&gt; inputSlots_;             // slots of inputs in tape\nslot_type outputSlot_;                          // slot of output in tape\n};\n</code></pre> <p>We declare it as a template for arbitrary tape types, which is good practice as it allows to reuse this implementation with higher order derivatives too.</p>"},{"location":"tutorials/external_functions/#computeexternal-method","title":"<code>computeExternal</code> Method","text":"<p>Within the <code>computeExternal</code> method, we first store the slots in the tape for the input variables, as we will need them during adjoint computation to increment the corresponding adjoints. We use the <code>inputSlots_</code> member vector to keep this information:</p> <pre><code>for (int i = 0; i &lt; n; ++i)\ninputSlots_.push_back(x[i].getSlot());\n</code></pre> <p>Then we create a copy of the active inputs and store them in a vector of passive values, with which we can call the external function:</p> <pre><code>std::vector&lt;value_type&gt; x_p(n);\nfor (int i = 0; i &lt; n; ++i)\nx_p[i] = value(x[i]);\nvalue_type y = sum_elements(&amp;x_p[0], n);\n</code></pre> <p>We now need to store this result in an active variable, register it as an output of the external function (to allow the tape to continue recording dependent variables), and keep its slot in the tape for the later adjoint computation:</p> <pre><code>active_type ret = y;\nTape::getActive()-&gt;registerOutput(ret);\noutputSlot_ = ret.getSlot();\n</code></pre> <p>Finally we need to insert the callback into the tape, hence requesting it to be called during adjoint rollback of the tape, and return:</p> <pre><code>Tape::getActive()-&gt;insertCallback(this);\nreturn ret;\n</code></pre>"},{"location":"tutorials/external_functions/#computeadjoint-method","title":"<code>computeAdjoint</code> Method","text":"<p>The <code>computeAdjoint</code> method gets called by XAD during tape rollback. We need to override this method and implement the manual adjoint code. For a simple sum operation, this is straightforward: all input adjoints are equal to the output adjoint since all partial derivatives are 1. Thus we need to obtain the output adjoint and increment all input adjoints by this value:</p> <pre><code>value_type output_adj = tape-&gt;getAndResetOutputAdjoint(outputSlot_);\nfor (int i = 0; i &lt; inputSlots_.size(); ++i)\ntape-&gt;incrementAdjoint(inputSlots_[i], output_adj); </code></pre> <p>The function <code>Tape::getAndResetOutputAdjoint</code> obtains the adjoint value corresponding to the given slot and resets it to zero. This reset is necessary in general as the output variable may have been overwriting other values in the forward computation. The <code>Tape::incrementAdjoint</code> function simply increments the adjoint with the given slot by the given value.</p>"},{"location":"tutorials/external_functions/#wrapper-function","title":"Wrapper Function","text":"<p>With the checkpointing callback class in place, we can implement a <code>sum_elements</code> overload for <code>AReal</code> that wraps the creation of this callback::</p> <pre><code>template &lt;class T&gt;\nxad::AReal&lt;T&gt; sum_elements(const xad::AReal&lt;T&gt;* x, int n)\n{\ntypedef typename xad::AReal&lt;T&gt;::tape_type tape_type;\ntape_type* tape = tape_type::getActive();\nExternalSumElementsCallback&lt;tape_type&gt;* ckp = new ExternalSumElementsCallback&lt;tape_type&gt;;\ntape-&gt;pushCallback(ckp);\nreturn ckp-&gt;computeExternal(x, n);\n}\n</code></pre> <p>This function dynamically allocates the checkpoint callback object and lets the tape manage its destruction via the <code>Tape::pushCallback</code> function. This call simply ensures that the callback object is destroyed when the tape is destroyed, making sure that no memory is leaked. If the callback object was managed elsewhere, this call would not be necessary. It then redirects the computation to the <code>computeExternal</code> function of the checkpoint callback class. Using this wrapper class, the <code>sum_elements</code> function can be used for active types in the same fashion as the original external function <code>sum_elements</code> for <code>double</code>. Defining it as a template allows us to re-use this function for higher-order derivatives, should we need them in future.</p>"},{"location":"tutorials/external_functions/#call-site","title":"Call-Site","text":"<p>The call site then can be implemented as (assuming that <code>x_ad</code> is the vector holding the independent variables, already registered on tape):</p> <pre><code>tape.newRecording();\nstd::vector&lt;AD&gt; xsqr(n);\nfor (int i = 0; i &lt; n; ++i)\nxsqr[i] = x_ad[i] * x_ad[i];\nAD y = sqrt(sum_elements(xsqr.data(), n)); // calls external function wrapper\ntape.registerOutput(y);\nderivative(y) = 1.0;\ntape.computeAdjoints();\nstd::cout &lt;&lt; \"y = \" &lt;&lt; value(y) &lt;&lt; \"\\n\";\nfor (int i = 0; i &lt; n; ++i)\nstd::cout &lt;&lt; \"dy/dx\" &lt;&lt; i &lt;&lt; \" = \" &lt;&lt; derivative(x[i]) &lt;&lt; \"\\n\";\n</code></pre> <p>This follows exactly the same procedure as given in Basic Usage.</p> <p>See also</p> <p>This example is included with XAD (<code>external_function</code>).</p>"},{"location":"tutorials/external_functions/#external-function-for-forward-mode","title":"External Function For Forward Mode","text":"<p>Since forward mode involves no tape, a manual implementation of the derivative computation needs to be implemented together with computing the value. The manual derivatives can be updated directly in the output values using the <code>derivative</code> function.</p> <p>In our example, we can implement the external function in forward mode as:</p> <pre><code>template &lt;class T&gt;\nxad::FReal&lt;T&gt; sum_elements(const xad::FReal&lt;T&gt;* x, int n)\n{\ntypedef xad::FReal&lt;T&gt; active_type;\nstd::vector&lt;T&gt; x_p(n);\nfor (int i = 0; i &lt; n; ++i)\nx_p[i] = value(x[i]);\nT y_p = sum_elements(&amp;x_p[0], n);\nactive_type y = y_p;\nfor (int i = 0; i &lt; n; ++i)\nderivative(y) += derivative(x[i]);\nreturn y;\n}\n</code></pre> <p>We first extract the passive values from the <code>x</code> vector and call the external library function to get the passive output value <code>y_p</code>. This value is then assigned to the active output variable <code>y</code>, which also initializes its derivative to <code>0</code>.</p> <p>As we have a simple sum in this example, the derivative of the output is a sum of the derivatives of the inputs, which is computed by the loop in the end.</p> <p>See also</p> <p>This example is included with XAD (<code>external_function</code>).</p>"},{"location":"tutorials/higher_order/","title":"Higher-Order Derivatives","text":"<p>As explained in Algorithmic Differentiation Background: Higher Orders, higher order derivatives can be computed by nesting first order algorithmic differentiation techniques. For example, one can obtain second order by computing forward mode over adjoint mode. With XAD, this technique can be used directly to compute higher order derivatives.</p> <p>XAD's automatic differentiation interface structures (see AD Mode Interface) define second order mode data types for easy access. Types for third or higher orders need to defined manually from the basic first-order types.</p> <p>We will demonstrate second-order derivatives using forward-over-adjoint mode in the following.</p>"},{"location":"tutorials/higher_order/#example-algorithm","title":"Example Algorithm","text":"<p>For demonstration purposes, we use the same algorithm from Basic Usage:</p> <pre><code>template &lt;class T&gt;\nT f(T x0, T x1, T x2, T x3)\n{\nT a = sin(x0) * cos(x1);\nT b = x2 * x3 - tan(x1 - x2);\nT c = a + 2* b;\nreturn c*c;\n}\n</code></pre> <p>We are interested in derivatives at the point:</p> <pre><code>double x0 = 1.0;\ndouble x1 = 1.5;\ndouble x2 = 1.3;\ndouble x3 = 1.2;\n</code></pre>"},{"location":"tutorials/higher_order/#forward-over-adjoint","title":"Forward Over Adjoint","text":"<p>In this mode, we can compute all first-order derivatives (as a single output function derived with adjoints gives all first order derivatives), and the first row of the Hessian matrix of second order derivatives. The full Hessian is defined as:</p> \\[ \\pmb{H} = \\left[ \\begin{array}{cccc}     \\frac{\\partial^2 f}{\\partial x_0^2} &amp;      \\frac{\\partial^2 f}{\\partial x_0 \\partial x_1} &amp;     \\frac{\\partial^2 f}{\\partial x_0 \\partial x_2} &amp;     \\frac{\\partial^2 f}{\\partial x_0 \\partial x_3} \\\\[6pt]     \\frac{\\partial^2 f}{\\partial x_1 \\partial x_0} &amp;      \\frac{\\partial^2 f}{\\partial x_1^2} &amp;     \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} &amp;     \\frac{\\partial^2 f}{\\partial x_1 \\partial x_3} \\\\[6pt]     \\frac{\\partial^2 f}{\\partial x_2 \\partial x_0} &amp;      \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} &amp;     \\frac{\\partial^2 f}{\\partial x_2^2} &amp;     \\frac{\\partial^2 f}{\\partial x_2 \\partial x_3} \\\\[6pt]     \\frac{\\partial^2 f}{\\partial x_3 \\partial x_0} &amp;      \\frac{\\partial^2 f}{\\partial x_3 \\partial x_1} &amp;     \\frac{\\partial^2 f}{\\partial x_3 \\partial x_2} &amp;     \\frac{\\partial^2 f}{\\partial x_3^2}  \\end{array}\\right] \\] <p>Note that the Hessian matrix is typically symmetric, which can be used to reduce the amount of computation needed for the full Hessian.</p> <p>The first step is to set up the tape and active data types needed for this computation:</p> <pre><code>typedef xad::fwd_adj&lt;double&gt; mode;\ntypedef mode::tape_type tape_type;\ntypedef mode::active_type AD;\ntape_type tape;\n</code></pre> <p>Note that the active type for this mode is actually <code>AReal&lt;FReal&lt;double&gt;&gt;</code>.</p> <p>Now we need to setup the independent variables and register them:</p> <pre><code>AD x0_ad = x0;\nAD x1_ad = x1;\nAD x2_ad = x2;\nAD x3_ad = x3;\ntape.registerInput(x0_ad);\ntape.registerInput(x1_ad);\ntape.registerInput(x2_ad);\ntape.registerInput(x3_ad);\n</code></pre> <p>As we compute the second order using forward mode, we need to seed the initial derivative for the second order before running the algorithm:</p> <pre><code>derivative(value(x0_ad)) = 1.0;\n</code></pre> <p>The inner call to <code>value</code> takes the value of the outer type, i.e. it returns the value as the type <code>FReal&lt;double&gt;</code>, of which we set the derivative to <code>1</code>.</p> <p>Now we can start recording derivatives on the tape and run the algorithm:</p> <pre><code>tape.newRecording();\nAD y = f(x0_ad, x1_ad, x2_ad, x3_ad);\n</code></pre> <p>For the inner adjoint mode, we need to register the output and seed the initial adjoint with 1:</p> <pre><code>tape.registerOutput(y);\nvalue(derivative(y)) = 1.0;\n</code></pre> <p>Here, the inner call to <code>derivative</code> gives the derivative of the outer type, i.e. the derivative of the adjoint-mode active type. This is of type <code>FReal&lt;double&gt;</code>, for which we set the value to <code>1</code>.</p> <p>Next we compute the adjoints, which computes both the first and second order derivatives:</p> <pre><code>tape.computeAdjoints();\n</code></pre> <p>We can now output the result:</p> <pre><code>std::cout &lt;&lt; \"y = \" &lt;&lt; value(value(y)) &lt;&lt; \"\\n\";\n</code></pre> <p>And the first order derivatives:</p> <pre><code>std::cout &lt;&lt; \"dy/dx0 = \" &lt;&lt; value(derivative(x0_ad)) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx1 = \" &lt;&lt; value(derivative(x1_ad)) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx2 = \" &lt;&lt; value(derivative(x2_ad)) &lt;&lt; \"\\n\"\n&lt;&lt; \"dy/dx3 = \" &lt;&lt; value(derivative(x3_ad)) &lt;&lt; \"\\n\";\n</code></pre> <p>Note again that the inner call to <code>derivative</code> obtains the derivative of the outer active data type, hence it gives a <code>FReal&lt;double&gt;</code> reference that represents the first order adjoint value. We can get this value as a <code>double</code> using the <code>value</code> call.</p> <p>The second order derivatives w.r.t. <code>x0</code> can be obtained as:</p> <pre><code>std::cout &lt;&lt; \"d2y/dx0dx0 = \" &lt;&lt; derivative(derivative(x0_ad)) &lt;&lt; \"\\n\"\n&lt;&lt; \"d2y/dx0dx1 = \" &lt;&lt; derivative(derivative(x1_ad)) &lt;&lt; \"\\n\"\n&lt;&lt; \"d2y/dx0dx2 = \" &lt;&lt; derivative(derivative(x2_ad)) &lt;&lt; \"\\n\"\n&lt;&lt; \"d2y/dx0dx3 = \" &lt;&lt; derivative(derivative(x3_ad)) &lt;&lt; \"\\n\";\n</code></pre> <p>which 'unwraps' the derivatives of the first and second order active types.</p> <p>The result of the running the application for the given inputs is:</p> <pre><code>y      = 7.69565\ndy/dx0 = 0.21205\ndy/dx1 = -16.2093\ndy/dx2 = 24.8681\ndy/dx3 = 14.4253\nd2y/dx0dx0 = -0.327326\nd2y/dx0dx1 = -3.21352\nd2y/dx0dx2 = 0.342613\nd2y/dx0dx3 = 0.198741\n</code></pre> <p>Forward over adjoint is the recommended mode for second-order derivatives.</p> <p>See also</p> <p>This example is included with XAD (<code>fwd_adj_2nd</code>).</p>"},{"location":"tutorials/higher_order/#other-second-order-modes","title":"Other Second-Order Modes","text":"<p>Other second-order modes work in a similar fashion. They are briefly described in the following.</p>"},{"location":"tutorials/higher_order/#forward-over-forward","title":"Forward Over Forward","text":"<p>With forward-over-forward mode, there is no tape needed and the derivatives of both orders need to be seeded before running the algorithm. One element of the Hessian and one first-order derivative can be computed with this method, if the function has one output. The derivative initialization sequence in this mode is typically:</p> <pre><code>value(derivative(x)) = 1.0;   // initialize the first-order derivative\nderivative(value(x)) = 1.0;   // initialize the second-order derivative\n</code></pre> <p>After the computation, the first order derivative can be retrieved as:</p> <pre><code>std::cout &lt;&lt; \"dy/dx = \" &lt;&lt; derivative(value(y)) &lt;&lt; \"\\n\";\n</code></pre> <p>And the second order derivative as:</p> <pre><code>std::cout &lt;&lt; \"d2y/dxdx = \" &lt;&lt; derivative(derivative(y)) &lt;&lt; \"\\n\";\n</code></pre> <p>With different initial seeding, different elements of the Hessian can be obtained.</p>"},{"location":"tutorials/higher_order/#adjoint-over-forward","title":"Adjoint Over Forward","text":"<p>Here the inner mode is forward, computing one derivative in a tape-less fashion, and the outer mode is adjoint, requiring a tape. With this mode, we need to initialize the forward-mode derivative with:</p> <pre><code>value(derivative(x)) = 1.0;   // initialize the first-order derivative\n</code></pre> <p>As the derivative of the output corresponds to the first order result, we need to seed its derivative (i.e. the adjoint) after running the algorithm:</p> <pre><code>derivative(derivative(y)) = 1.0;\n</code></pre> <p>After tape interpretation, we can now obtain the first-order derivative as:</p> <pre><code>std::cout &lt;&lt; \"dy/dx = \" &lt;&lt; value(derivative(y)) &lt;&lt; \"\\n\";\n</code></pre> <p>Due to the symmetries in this mode of operation, the same first-order derivatives can also be obtained as:</p> <pre><code>std::cout &lt;&lt; \"dy/dx = \" &lt;&lt; derivative(derivative(x)) &lt;&lt; \"\\n\";\n</code></pre> <p>Which allows to get all first-order derivatives w.r.t. to all inputs in this mode, similar to the forward-over-adjoint mode.</p> <p>The second-order derivatives can be obtained as:</p> <pre><code>std::cout &lt;&lt; \"d2y/dxdx = \" &lt;&lt; derivative(value(x))\n</code></pre>"},{"location":"tutorials/higher_order/#adjoint-over-adjoint","title":"Adjoint Over Adjoint","text":"<p>As both nested modes are adjoint, this mode needs to two tapes for both orders. Hence the types defined in the interface structure <code>adj_adj</code> need an inner and an outer tape type:</p> <pre><code>typedef xad::adj_adj&lt;double&gt; mode;\ntypedef mode::inner_tape_type inner_tape_type;\ntypedef mode::outer_tape_type outer_tape_type;\ntypedef mode::active_type AD;\n</code></pre> <p>In this mode, no initial derivatives need to be set, but it is important that both tapes are initialized and a new recording is started on both before running the algorithm.</p> <p>After the execution, the outer derivative needs to be seeded as:</p> <pre><code>value(derivative(y)) = 1.0;\n</code></pre> <p>And then the outer tape needs to compute the adjoints. This computes the <code>value(derivative(x))</code> as an output, and the derivative of this needs to be set before interpreting the inner tape:</p> <pre><code>derivative(derivative(x)) = 1.0;\n</code></pre> <p>After calling <code>computeAdjoints()</code> on the inner tape, we can read the first-order derivatives as:</p> <pre><code>std::cout &lt;&lt; \"dy/dx = \" &lt;&lt; value(derivative(x)) &lt;&lt; \"\\n;\n</code></pre> <p>And the second-order derivatives as:</p> <pre><code>std::cout &lt;&lt; \"d2y/dxdx\" &lt;&lt; derivative(value(x)) &lt;&lt; \"\\n\";\n</code></pre>"},{"location":"tutorials/smoothed_math/","title":"Handling Discontinuities","text":"<p>Many functions have jumps or discontinuities at which points no mathematical derivatives exist. These are typically written as conditionals in the source code or by using the math functions <code>abs</code>, <code>max</code>, or <code>min</code>.</p> <p>XAD generally defines the derivatives of standard math functions as the average of the left and right derivatives at the discontinuity points. For example, the derivative of <code>abs(x)</code> at point <code>x = 0</code> is set to <code>0</code>, as the left derivative is <code>-1</code> and the right derivative is <code>1</code>.</p> <p>As this definition is not mathematically accurate, and as this creates problems with higher order derivatives, XAD provides a set of smoothed math functions which are differentiable at all points and can be used as a replacement for the original function. They are implemented to provide accurate derivatives outside a small area around the discontinuity, and approximate the original function using a spline within this area.</p> <p>As an example, the <code>smooth_abs</code> function is illustrated in the figure below (with <code>c = 0.001</code>):</p> <p></p> <p>Note that discontinuities may be hidden in conditional constructs in the original code. In order to benefit from the smoothed math functions, the conditionals need to be replaced by functions. For example:</p> <pre><code>// original code\ndouble y = 0;\nif (value &gt; strike)\ny = value - strike;\n// equivalent smoothed code\ndouble y = smooth_max(0, value - strike);\n</code></pre> <p>A reference of all provided smoothed math functions is given in Smoothed Math Functions.</p>"}]}